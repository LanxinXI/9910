---
title: "DEA and data cleaning"
author: "LANXIN XI"
date: "`r Sys.Date()`"
output: word_document
---
# Introduction

Providing care to critical patients, intensive care units (ICU) are one of the departments where care work is most demanded and the medical resources are most concentrated [1]. Patient outcomes have always been concerned, especially in-hospital mortality and length of stay, as important evidence for optimizing medical resources allocation and improving care efficiency. 
Previous studies led to the suggestion that different disciplinary ICUs presents differences in in-hospital mortality. A study by Afessa et al. [2] reported different in-hospital mortality in medical ICU, surgical ICU and mixed ICU according to the analysis on APACHE III database. Park et al. [3] reported interesting outcomes that surgical ICU patients are less likely to die than the medical ICU patients even though the higher likelihood of experiencing more harm.
The length of stay (LOS) in ICU is associated with care burden [4], prolonged ICU stay results in higher care costs and medical resources utilization[1]. It has been reported that various clinical indicators and patients demographics are associated with LOS[5]. Open source datasets and prospectively collected data have been used to predict ICU LOS [6-8] and present that the prediction of ICU LOS and long-term hospitalization risk is effective.
This project focused on two research questions: i) the association between the ICU type of the first ICU stay and adult patient in-hospital mortality outcome; ii) the prediction of the prolonged ICU stays (≥7 day) of adult patient with patient demographics and ICU bedside measurements in the first 24 hours in ICU.

The objectives of this project are to : i) estimate the total effect of ICU type of the first ICU stay on the  adult patients in-hospital mortality outcomes; ii)predict the risk of adult patients' prolonged ICU stays (≥7 day) with ICU bedside measurements in the first 24 hours in ICU.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)
library(readr)
library(janitor)
library(patchwork)
library(naniar)
library(forcats)
library(comorbidity)
library(scales)
library(mice)
library(ggcorrplot)
library(ggpubr)
library(lme4)
library(pROC)
library(ResourceSelection)
library(lmtest)
library(rms)
library(rmda)
library(car)
library(fastDummies)
library(xgboost)
library(rsample)
library(caret)
library(gtsummary)
library(broom)
library(kableExtra)
library(glmnet)
library(SHAPforxgboost)
```



```{r Data loading, echo=FALSE}
###############################################################################
###################### Data loading and preparation ###########################
###############################################################################
admissions <- readr::read_csv("../data/mimic_data/admissions.csv")
patients <- readr::read_csv("../data/mimic_data/patients.csv")
icustays <- readr::read_csv("../data/mimic_data/icustays.csv")
pt_icu_outcome <- readr::read_csv("../data/mimic_data/pt_icu_outcome.csv")
transfers <- readr::read_csv("../data/mimic_data/transfers.csv")
vitals_hourly <- readr::read_csv("../data/mimic_data/vitals_hourly.csv")
gcs_hourly <- readr::read_csv("../data/mimic_data/gcs_hourly.csv")
pv_mechvent <- readr::read_csv("../data/mimic_data/pv_mechvent.csv")
labs_hourly <- readr::read_csv("../data/mimic_data/labs_hourly.csv")
output_hourly <- readr::read_csv("../data/mimic_data/output_hourly.csv")
icd9_diag <- readr::read_csv("../data/mimic_data/icd9_diag.csv")

```
```{r}
dim(pt_icu_outcome)
```

```{r}
# Check the duplicate ICU stay `229922`
duplicated_patient <- pt_icu_outcome %>%
  filter(icustay_id == 229922)
print(duplicated_patient)

duplicated_t <- labs_hourly %>%
  filter(icustay_id == 229922)
print(duplicated_t)
```

```{r}
# Remove the duplicated record
pt_icu_outcome <- pt_icu_outcome %>%
  filter(!(icustay_id == 229922 & admittime == as.POSIXct("2185-12-02 23:53:00", tz = "UTC")))

duplicated_patient_cleaned <- pt_icu_outcome %>%
  filter(icustay_id == 229922)
print(duplicated_patient_cleaned)
```

```{r}
dim(pt_icu_outcome)

```

# Question 1

## Q1.1 Methods
### Q1.1.1 Data source and cohort

MIMIC-III v1.4 [9] (Medical Information Mart for Intensive Care III) is the data set used in this project，which is a large, freely-available database comprising health related data associated with patients who stayed within ICUs of the Beth Israel Deaconess Medical Center during the period 2001-2012.
The data contains 53423 distinct hospital admissions, and during each admission a patient could have stayed in ICU more than once. The project start with 61532 total ICU stay encounters after removing a duplicated ICU stay encounter (unique ICU stay ID = 229922).
In this question, the analysis was based on unique adult patient's first ICU stay encounter among the patient's all ICU encounters, which resulted in a total of 38509 unique ICU stay. The admissions without clear hospital outcome are also remove, resulting in 32,245 unique ICU stay.

```{r Link the main data tables}
###############################################################################
###################### Data preprocessing and EDA ###########################
###############################################################################
# Retain the first ICU records of each patient's all ICU records

data_filter <- pt_icu_outcome |>  
  
  group_by(subject_id) |>
  slice_min(intime, n =1, with_ties = FALSE) |>
  ungroup()
dim(data_filter)

# Filter records of patients age >= 18
data_filter <- data_filter |>
  filter(age_years >= 18)

dim(data_filter)

# Ensure exist of hospital outcome
data_filter <- data_filter |>   

  filter(!is.na(hospital_expire_flag))

dim(data_filter)


```


### Q1.1.2 Variables

The outcome in this question was define as the in hospital outcome and the exposure ICU type was defined as the first care unit in one unique ICU stay encounter, including Cardiac Care Unit(CCU), Cardiac Surgery Unit(CSRC), Medical Intensive Care Unit(MICU), Neuro Intensive Care Unit(NICU), Surgical Intensive Care Unit(SICU) and Trauma Surgical Intensive Care Unit (TSICU). To estimate the total effect of ICU type on the in-hospital mortality outcome, the potential confounders will be controlled while the potential intermediate variables were avoided to be controlled (Greenland, 1999). Besides the important demographics (e.g. age, gender, ethnicity) and administrative (e.g. admission type, insurance), the variable selection of potential confoundings is based on SOFA/APACHE indicators. SOFA and APACHE are widely used in predicting  mortality of patients in different subspecialties, especially in ICU (Shahi, 2024; Moreno, 2023). SOFA consists of indicators cover six main systems of respiratory, coagulation, hepatic, cardiovascular, central nervous and renal system, while APACHE also emphasis vital signs and gastric chronic diseases (Vincent, 1996; Knaus, 1985).  According to the temporal sequence principle (Baker,2014), confounding factors must be measured before or simultaneously with exposure, only the vital signs and lab measurements collected within the first 24 hours after patients were enrolled to ICU were used. The extreme values that can best reflect the severity of the patient's condition were created as the representative value with in the 24h time window. Table 1 summarizes all the covariates that will be considered. The vital signs include heart rate, O2 saturation pulse oxymetry, respiratory rate, systolic blood pressure, mean arterial pressure, body temperature, Glasgow Coma Scales (GCS) and glucose. Laboratory measurements include creatinine, platelets and bilirubin.

插入表格图片


#### GCS 
The minimum with 24 hr
```{r gcs}

summary(gcs_hourly)

gcs_24hr_min <- gcs_hourly |>
  filter(hr >= 0 & hr <= 24) |>  # Filter gcs score within 24hr
  group_by(icustay_id) |>
  summarise(
    min_gcs_24h = min(gcs, na.rm = TRUE) # Extract the minimum gcs within 24hr
  ) |>
  ungroup()

```
#### Bedside measurements
```{r}
summary(vitals_hourly)
```
```{r}
# Adress the outliers
clean_limits_vitals <- list(
  
  meanarterialpressure = c(20, 140),
  sysbp = c(40, 260),
  heartrate = c(20, 250),
  resprate = c(5, 80),
  spo2 = c(50, 100),
  temperature = c(30, 43),
  glucose = c(40, 600)
 
)


vitals_hourly_clean <- vitals_hourly

for (v in names(clean_limits_vitals)) {
  lo <- clean_limits_vitals[[v]][1]
  hi <- clean_limits_vitals[[v]][2]
  vitals_hourly_clean[[v]] <- ifelse(vitals_hourly_clean[[v]] < lo | vitals_hourly_clean[[v]] > hi, NA, vitals_hourly_clean[[v]])
}

```

```{r}
summary(vitals_hourly_clean)
```


```{r}
vital_24hr <- vitals_hourly_clean |>
  filter(hr >= 0 & hr <= 24) |>
  group_by(icustay_id) |>
  summarise(
    min_map_24h = min(meanarterialpressure, na.rm = TRUE),
    min_sysbp_24h = min(sysbp, na.rm = TRUE),
    max_hr_24h = max(heartrate, na.rm = TRUE),
    max_resp_24h = max(resprate, na.rm = TRUE),
    min_temp_24h = min(temperature, na.rm = TRUE),
    max_temp_24h = max(temperature, na.rm = TRUE),
    max_glucose_24h = min(glucose, na.rm = TRUE),
    min_spo2_24h = min(spo2, na.rm = TRUE),
    
  ) |>
  ungroup()


```
#### lab measurements
```{r}
# Adress the outliers
clean_limits_labs <- list(
  
 bilirubin = c(0, 40),
 platelets = c(1, 1000),
 creatinine = c(0.1, 15)
 
)


labs_hourly_clean <- labs_hourly

for (v in names(clean_limits_labs)) {
  lo <- clean_limits_labs[[v]][1]
  hi <- clean_limits_labs[[v]][2]
  labs_hourly_clean[[v]] <- ifelse(labs_hourly_clean[[v]] < lo | labs_hourly_clean[[v]] > hi, NA, labs_hourly_clean[[v]])
}

```

```{r}
summary(labs_hourly_clean)
```

```{r}
lab_24hr <- labs_hourly_clean |>
  filter(hr >= -24 & hr <= 24 ) |>
  group_by(icustay_id) |>
  summarise(
    max_creatinine_24h = max(creatinine, na.rm = TRUE),
    min_platelets_24h = min(platelets, na.rm = TRUE),
    max_bilirubin_24h = max(bilirubin, na.rm = TRUE)
  )


```
#### Comorbidity
```{r}
icd9_diag <- as.data.frame(icd9_diag)
icd9_diag$hadm_id <- as.character(icd9_diag$hadm_id)
icd9_diag$icd9_code <- gsub("\\.", "", icd9_diag$icd9_code) 
icd9_diag$icd9_code <- as.character(icd9_diag$icd9_code)
icd9_for_comorb <- icd9_diag[grepl("^[0-9]", icd9_diag$icd9_code), ]
```

```{r}
elixhauser <- comorbidity(
  x = icd9_for_comorb,
  id = "hadm_id",
  code = "icd9_code",
  map = "elixhauser_icd9_quan",
  assign0 = TRUE
)

```

```{r}
comorbidity_groups <- elixhauser |>
  mutate(
    comorb_cardio = as.integer(chf == 1 | carit == 1 | valv == 1 | pcd == 1 | pvd == 1),
    comorb_renal = as.integer(rf == 1),
    comorb_pulm = as.integer(hypunc == 1 | hypc == 1), 
    comorb_diabetes = as.integer(diabunc == 1 | diabc == 1),
    comorb_cancer = as.integer(solidtum == 1 | metacanc == 1 | lymph == 1),
    comorb_liver = as.integer(ld == 1),
    comorb_other = as.integer(aids == 1 | rheumd == 1)
  ) |>
  select(hadm_id, comorb_cardio, comorb_renal, comorb_pulm, comorb_diabetes, comorb_cancer, comorb_liver, comorb_other)

comorbidity_groups$hadm_id = as.numeric(comorbidity_groups$hadm_id)
comorbidity_groups$comorb_cardio = as.factor(comorbidity_groups$comorb_cardio)
comorbidity_groups$comorb_renal = as.factor(comorbidity_groups$comorb_renal)
comorbidity_groups$comorb_pulm = as.factor(comorbidity_groups$comorb_pulm)
comorbidity_groups$comorb_diabetes = as.factor(comorbidity_groups$comorb_diabetes)
comorbidity_groups$comorb_cancer = as.factor(comorbidity_groups$comorb_cancer)
comorbidity_groups$comorb_liver = as.factor(comorbidity_groups$comorb_liver)
comorbidity_groups$comorb_other = as.factor(comorbidity_groups$comorb_other)

head(comorbidity_groups)

```

#### Merge the confounder variabels to the main dataframe
```{r Create the analysis dataframe for Question 1}
# Select useful variables from the "data_merge"
data_merge <- data_filter |>
  # Link the data tables with demographic information data
  left_join(
    icustays |> select(icustay_id, first_careunit),
    by = "icustay_id"
  ) |>
  mutate(
    icu_type = as.factor(first_careunit)
  ) |>
  
  left_join(
    patients |> select(subject_id, gender),
    by = "subject_id"
  ) |>
  
  left_join(
    admissions |> select(hadm_id, admission_type, insurance, ethnicity),
    by = "hadm_id"
  ) |>
  select(subject_id, hadm_id, icustay_id, age_years, gender, icu_type, admission_type, insurance, ethnicity, hospital_expire_flag) |>
  
  # Add the confounder variables to the dataframe
  left_join(gcs_24hr_min, by = "icustay_id") |>
  left_join(vital_24hr, by = "icustay_id") |>
  left_join(lab_24hr, by = "icustay_id") |>
  left_join(comorbidity_groups, by = "hadm_id") |>
  mutate(
    death = as.factor(hospital_expire_flag), 
    gender = as.factor(gender),               
    insurance = as.factor(insurance),         
    ethnicity = as.factor(ethnicity),         
    admission_type = as.factor(admission_type),
    # Recode the ethnicity
    ethnicity = case_when(
      str_detect(ethnicity, "WHITE") ~ "WHITE",
      str_detect(ethnicity, "BLACK|AFRICAN AMERICAN") ~ "BLACK",
      str_detect(ethnicity, "HISPANIC|LATINO") ~ "HISPANIC",
      TRUE ~ "OTHER/UNKNOWN"
    ),
    ethnicity = as.factor(ethnicity)
  ) 
```


```{r}
###############################################################################
###################### EDA and further preprocessing ###########################
###############################################################################
# Sanity check
dim(data_merge)
str(data_merge)
summary(data_merge)
```

#### Check missing values
```{r Visualize the missing values}
####################################################
#            Visualize the missing values          #
####################################################

# Initialize a data frame
missing_report_final <- data.frame(
  variable = character(),
  na_count = numeric(),
  na_percent = character(),
  stringsAsFactors = FALSE
)

# A loop to count missing values in all variables
for (col_name in names(data_merge)) {
  current_col <- data_merge[[col_name]]
  
  count <- sum(is.na(current_col))
  
  ratio <- mean(is.na(current_col))
  
  new_row <- data.frame(
    variable = col_name,
    na_count = count,
    na_percent = scales::percent(ratio, accuracy = 0.1),
    stringsAsFactors = FALSE
  )
  
  missing_report_final <- bind_rows(missing_report_final, new_row)
}

missing_report_final <- missing_report_final %>%
  arrange(desc(na_count))

print(missing_report_final)
```

#### Check the distribution of all variables
```{r}
#################################################
# Check the distribution of continuous variables#
#################################################
con_vars <- c("age_years", "min_gcs_24h", "min_map_24h", "min_sysbp_24h",
              "max_hr_24h", "max_resp_24h", "min_temp_24h", "max_temp_24h", 
              "max_glucose_24h", "min_spo2_24h", "max_creatinine_24h", "min_platelets_24h",
              "max_bilirubin_24h" )

for (var in  con_vars){
  plot_data <- data_merge |>
    filter(!is.na(!!sym(var)))
  
  if (nrow(plot_data) > 10) {
    p <- ggplot(plot_data, aes(x =!!sym(var))) +
      geom_histogram(aes(y = after_stat(density)), bins = 30, fill = "#0072B2", alpha = 0.7) +
      geom_density(color = "orange", linewidth = 1) +
      labs(
        title = paste("Distribution:", var, "(No NA)"),
        subtitle = paste("Observations:", nrow(plot_data)),
        x = var, 
        y = "Density"
      ) +
      theme_minimal()
    
    print(p)
  } else
    cat(paste(var, "has no more than 10 observations with values."))
}
```


```{r}
#################################################
# Check the distribution of categorical variables#
#################################################
cat_vars <- c("icu_type", "gender", "admission_type", "insurance", "ethnicity", 
              "death", "comorb_cardio", "comorb_renal", 
              "comorb_pulm", "comorb_diabetes", "comorb_cancer", "comorb_liver", 
              "comorb_other" )


format_percent <- function(x, digits = 1){
  paste0(round(x * 100, digits), "%")
}

for (var in cat_vars) {
  freq_table <- table(data_merge[[var]], useNA = "always")
  prop_table <- prop.table(freq_table)
  
  report <- data.frame(
    Category = names(freq_table),
    Count = as.vector(freq_table),
    Percent = format_percent(as.vector(prop_table)),
    stringsAsFactors = FALSE
  )
  
  
  print(report, row.names = FALSE)
}
```




#### Check the correlation between continuous variables

```{r}
cor_mat <- cor(data_merge[, con_vars], use = "pairwise.complete.obs", method = "spearman")

var_order <- colnames(cor_mat)              
cor_df <- as.data.frame(cor_mat)
cor_df$var1 <- rownames(cor_df)

cor_long <- cor_df |>
  pivot_longer(-var1, names_to = "var2", values_to = "corr") |>
  mutate(
    var1 = factor(var1, levels = rev(var_order)),  
    var2 = factor(var2, levels = var_order)
  )

ggplot(cor_long, aes(var2, var1, fill = corr)) +
  geom_tile(color = "white") +
  geom_text(aes(label = sprintf("%.2f", corr)), size = 3) +
  scale_fill_gradient2(low = "#E57373", mid = "white", high = "#4DB6AC", limits=c(-1,1)) +
  coord_fixed() +
  labs(x="", y="", title="Spearman Correlation (Cleaned Data)") +
  theme_bw() +
  theme(axis.text.x = element_text(angle=45, hjust=1))
```

### Relationship between in-hospital outcome and continuous variables

```{r}
vars_demo <- c("age_years")
vars_hemo <- c("min_map_24h","min_sysbp_24h","max_hr_24h")
vars_resp <- c("max_resp_24h","min_spo2_24h")
vars_temp <- c("min_temp_24h","max_temp_24h")
vars_lab  <- c("max_glucose_24h","max_creatinine_24h","min_platelets_24h","max_bilirubin_24h")
vars_neuro <- c("min_gcs_24h")

make_box <- function(df, vars, title){
  df |>
    select(death, all_of(vars)) |>
    pivot_longer(-death, names_to="variable", values_to="value") |>
    ggplot(aes(x=factor(death), y=value, fill=factor(death))) +
    geom_violin(trim=FALSE, alpha=0.3) +
    geom_boxplot(width=0.2, outlier.alpha = 0.2) +
    stat_compare_means(method="wilcox.test", label="p.signif") +
    facet_wrap(~variable, scales="free", ncol=3) +
    scale_fill_manual(values=c("#E57373","#4DB6AC")) +
    labs(title=title, x="Death", y="Value") +
    theme_bw(base_size=12) +
    theme(legend.position="none",
          strip.text = element_text(face="bold"))
}

make_box(data_merge, vars_demo, "Demographics")
make_box(data_merge, vars_hemo, "Hemodynamic Variables")
make_box(data_merge, vars_resp, "Respiratory Variables")
make_box(data_merge, vars_temp, "Temperature Variables")
make_box(data_merge, vars_lab,  "Laboratory Results")
make_box(data_merge, vars_neuro,"Neurologic Status")
```

#### ICU Type vs in-hospital outcome
```{r}
data_merge |>
  group_by(icu_type) |>
  summarise(
    mortality = mean(ifelse(death == 1, 1, 0)) * 100,
    n = n()
  ) |>
  arrange(desc(mortality))
```


## Q1.1.3 Outliers and missing data handling
Exploratory data analysis and data cleaning were performed  through the whole data preprocessing. Errors can appear in data collection and entry, sanity check suggested that extreme outliers that exceed the reasonable physiological range existed in the original vital signs and laboratory measurements data. For all continuous indicators, reasonable ranges were defined and any data points exceeding the ranges were regarded as data entry errors and marked as missing values (NA).
Thorough missing data analysis were performed on the merged data and reported that extreme high missing rates over 85% in bedside measured vital signs including heart rate (max), SpO2 (min), respiratory rate (max), mean arterial pressure (min), body temperature (max & min), systolic blood pressure (min) and glucose (max). Bilirubin, platelets, GCS and creatinine had extremely low missing rate lower than 2%. The 2 observations with missing comorbidity information were deleted from the cohort, resulting in 32243 samples. Missing pattern check and visualization suggested that missing of vital signs presented no statistically significant relationships with the ICU type and in-hospital outcomes. The assumption that no measurement indicating rather stable condition was accepted and normal value imputation was applied on bedside measurements and low missing rate variables.high synchronization, with a missing correlation coefficient close to 1.  Given the joint missingness of vital signs, instead of creating separate missing markers for each variable, a new continuous variable was created to represent the number of missing indicators in vital signs covariates with high missing rates to avoid potential multilinearity caused by creating separate missing flags for each variable.


#### Check missing pattern

```{r}
vis_miss(data_merge, warn_large_data = FALSE) 

```

```{r}
library(UpSetR)
vars_high <- c("min_temp_24h","max_temp_24h","max_glucose_24h",
               "max_resp_24h","min_sysbp_24h","min_map_24h",
               "max_hr_24h","min_spo2_24h")

library(corrplot)

mat <- is.na(data_merge[vars_high]) * 1
corr <- cor(mat)
corrplot(corr, method = "color", tl.col="black", tl.cex = 0.8)
```

```{r}
# Check the missing pattern
vars_test <- c("min_map_24h","min_spo2_24h","max_hr_24h","max_resp_24h","min_sysbp_24h","max_glucose_24h", "min_temp_24h", "max_temp_24h")

for(v in vars_test){
  data_merge[[paste0("miss_",v)]] <- as.integer(is.na(data_merge[[v]]))
  print(v)
  print(summary(glm(data_merge[[paste0("miss_",v)]] ~ death + icu_type +age_years,
                    data=data_merge, family=binomial)))
}

```

```{r}
data_analy_clean <- data_merge |>
  filter(!if_any(starts_with("Comorb_"), is.na))
dim(data_merge)
```
```{r}
vitals_missing_vars <- c("min_temp_24h", "max_temp_24h", "max_glucose_24h", "max_resp_24h", "min_sysbp_24h", "min_map_24h", "max_hr_24h", "min_spo2_24h")
```

```{r}
data_imputed_normal <- data_merge |>
  mutate(
    vitals_missing_count = rowSums(across(all_of(vitals_missing_vars), ~ is.na(.x)))
  ) |>
  mutate(
     min_temp_24h = replace_na(min_temp_24h, 37.0),
     max_temp_24h = replace_na(max_temp_24h, 37.0),
     max_glucose_24h = replace_na(max_glucose_24h, 120),
     max_resp_24h = replace_na(max_resp_24h, 18),
     min_sysbp_24h = replace_na(min_sysbp_24h, 100),
     min_gcs_24h = replace_na(min_gcs_24h, 15),
     max_creatinine_24h = replace_na(max_creatinine_24h, 1.0), 
     min_map_24h = replace_na(min_map_24h, 70), 
     max_hr_24h = replace_na(max_hr_24h, 90),
     min_spo2_24h = replace_na(min_spo2_24h, 98),
     min_platelets_24h = replace_na(min_platelets_24h, 200),
     max_bilirubin_24h = replace_na(max_bilirubin_24h, 0.6)
     
   ) |>
   mutate(
     across(ends_with("flag"), as.factor)
   )

```

```{r}
dim(data_imputed_normal)
```

```{r}
colSums(is.na(data_imputed_normal))
```
```{r}
data_imputed_normal$icu_type <- relevel(data_imputed_normal$icu_type, ref = "MICU")
```



```{r}
vars_mice_model <- c("max_bilirubin_24h", "death", "icu_type", "age_years", "gender", "ethnicity", "admission_type", "insurance", "comorb_cardio", "comorb_renal", "comorb_pulm", "comorb_diabetes", "comorb_cancer", "comorb_other","comorb_liver", "min_gcs_24h", "min_platelets_24h", "max_creatinine_24h", "min_map_24h", "max_hr_24h", "min_spo2_24h", "max_resp_24h","min_sysbp_24h", "min_temp_24h", "max_temp_24h", "max_glucose_24h",  "vitals_missing_count", "max_bilirubin_24h_missing_flag"  )

data_imp <- data_imputed_normal[, vars_mice_model]


initial <- mice(data_imp, maxit = 0)
meth <- initial$method
pred <- initial$predictorMatrix

meth[] <- ""

meth["max_bilirubin_24h"] <- "pmm"

pred[,] <- 0

pred["max_bilirubin_24h", c("death", "icu_type", "age_years")]
imp <- mice(data_imp, m = 5, mthod = meth, predictorMatrix = pred, seed = 42)
```
```{r}
comp1 <- complete(imp, 1)
data_imputed_mice <- data_imputed_normal
data_imputed_mice$max_bilirubin_24h_imp <- comp1$max_bilirubin_24h
```

```{r}
dim(comp1)
dim(data_imputed_mice)
```


```{r}
p_map <- data_imputed_normal %>%
  ggplot(aes(x = min_map_24h)) +
  geom_histogram(bins = 50, fill = "#4DB6AC", color = "black") +
  geom_vline(xintercept = 70, color = "#E57373", linetype = "dashed", linewidth = 1) +
  labs(title = "min_map_24h distribution after inputation (red)", x = "MAP (mmHg)", y = "Frequency") +
  theme_minimal()

print(p_map)  
```
### Q1.1.4 Statistical analysis and model selection
Multivariable logistic regression model were built to estimate ICU type total effect on binary in-hospital outcome. According to EDA results that MICU presented the largest sample size of 10,937 and the highest crude mortality rate, MICU is defined as the reference category in the logistic models.

插入模型公式

Given the use of MICE, the model with MICE imputed variables will be fitted on MICE completed data separately and the coefficients, standard errors and confidence intervals of the final model will be merged using Rubin's Rules.

Progressive multivariate regression method was applied to fit 3 nested models(Table). The main model of this question is Model 2 which included all confounding factors.

插入表格



### Q1.1.5 Model diagnostics
Use variance inflaction factor (VIF) to evaluate multicollinearity between independent variables. VIF > 5 would be regarded as severe collinearity, and the variables would be combined with other variables or excluded. 
Cook's Distance (Cook, 1977) was calculated to examine if there were any single points that had excessive and systematic impact on the estimated coefficients, and 0.01 was defined as the threshold. 
Hosmer-Lemeshow test (Hosmer, 1980) was used to evaluate the goodness-of-fit, and P-value>0.05 was acceptable, indicating that the model fitting of the data is sufficient and acceptable. Studies reported that the hypothesis of perfect fit is more likely to be rejected when testing with large sample size (Nattino, 2018; Liu, 2020). Given the large cohort in the study, 5000 observations were sampled to perform the test. 
Although the model is not used to predict, the discriminative ability was also evaluated by ROC and AUC. The higher AUC value indicates the better ability to distinguish different outcomes.
VIF, Hosmer-Lemeshow test and AUC were evaluated on all 5 imputed data set, Cook's Distance was calculated on one representative imputed data set.
Another two models were fitted to perform sensitivity analysis to test the robustness of the main model. Model 3 excluded covariates with missing rate higher than 50% and was fitted with the complete cases. Model 4 included all covariates and was fitted with complete samples.

插入Model3 和 Model4

## Q1.2 Results
### Q1.2.1 Descriptive statistics of cohort
Totally 32,243 ICU stay encounters are included in the analysis, among which MICU had most ICU stays (n = 10.937, 34.0%). The overall age mean of the patients was 63.2 (17.5), and CCU patients had the highest age mean of 67.9. Most of the patients (80.0%) were admitted to the hospital through emergency. There were significant differences in the burden of comorbidities among patients of various ICU types. Most  patients payed though  Medicare (52.3%) or private (35.1%) insurance. Cardiovascular comorbidity is the most common in CCU (74.3%), while the proportion pulmonary comorbidity reached 67.1%. White people are the majority population. As for the in-hospital outcomes, the overall in-hospital mortality was 4.5% and there were statistically significant differences (P < 0.001) between the mortality rates of various ICU types. MICU had the highest mortality rate of 6.8%, while CSICU had the lowest mortality rate of 1.4%.


```{r}
# Use`data_imputed_normal`, n = 32243
str(data_imputed_normal)
```
```{r}

demo_vars <- c("age_years", "gender", "icu_type", "admission_type", "insurance", "ethnicity", "comorb_cardio", "comorb_renal", "comorb_pulm", "comorb_diabetes", "comorb_cancer", "comorb_liver", "comorb_other", "death")

data_imputed_normal |>
  select(all_of(demo_vars)) |>
  mutate(
    across(starts_with("comorb_"), ~factor(.x, levels = c("0","1"), labels = c("No","Yes"))),
    death = factor(death, levels = c(0, 1,"0", "1"), labels = c("Alive","Died","Alive","Died"))
  ) |>
  tbl_summary(
    by = "icu_type",
    statistic = list(
      all_continuous() ~ "{mean} ({sd})",
      all_categorical() ~ "{n} ({p}%)"
    ),
    digits = list(
      all_continuous() ~ 1, 
      all_categorical() ~ 1
    ),
    missing = "ifany",
    label = list(
      age_years ~ "Age (years)",
      gender ~ "Gender",
      admission_type ~ "Admission Type", 
      insurance ~ "Insurance",
      ethnicity ~ "Ethnicity",
      comorb_cardio ~ "Cardiovascular Comorbidity", 
      comorb_renal ~ "Renal Comorbidity",
      comorb_pulm ~ "Pulmonary Comorbidity", 
      comorb_diabetes ~ "Diabetes", 
      comorb_cancer ~ "Cancer", 
      comorb_liver ~ "Liver Disease", 
      comorb_other ~ "Other Comorbidity",
      death ~ "In-hospital Outcome"
    )
  ) |>
  add_overall(last = TRUE) |>
  add_p() |>
  modify_header(label = "**Variable**") |>
  bold_labels()
```




(1) Model0: Modelling with only `icu_type` included as independent variable on the imputed data
(2) Model1: Model0 + Demographics
(3) Model2: Model1 + Comorbidity + severity of disease( Vital signs & Lab measurements) + Missing flags
(3) sensitivity model removing variables with >50% missingness and performing complete-case analysis,
(4) complete-case full-variable model including all predictors without imputation.
```{r}
data_imputed_mice$icu_type <- relevel(data_imputed_mice$icu_type, ref = "MICU")
```

#### Model 0 modelling with only ICU type on imputed data
```{r}
mod0 <- glm(death ~ icu_type, data = data_imputed_mice, family = binomial)

summary(mod0)
```

```{r}
exp(cbind(OR = coef(mod0), confint(mod0)))
```

#### Model 1: mod0 + demographics on imputed data
```{r}
mod1 <- glm(death ~ icu_type + age_years + gender + ethnicity + admission_type + insurance, data = data_imputed_mice, family = binomial)

summary(mod1)

```

```{r}
exp(cbind(OR = coef(mod1), confint(mod1)))
```

#### Model 2 mod1 + comorbidity + severity of disease on imputed data
```{r}
  
demographic_comorbidity <- "age_years + gender + ethnicity + admission_type + insurance + comorb_cardio + comorb_renal + comorb_pulm + comorb_diabetes + comorb_cancer + comorb_other + comorb_liver"

imputed_vars <- "min_gcs_24h + min_platelets_24h + max_creatinine_24h + min_map_24h + max_hr_24h + min_spo2_24h + max_resp_24h + min_sysbp_24h + min_temp_24h + max_temp_24h + max_glucose_24h + max_bilirubin_24h"

missing_flags <- "vitals_missing_count + max_bilirubin_24h_missing_flag"

formula <- paste("death ~ icu_type +", demographic_comorbidity, "+", imputed_vars, "+", missing_flags )

cat(formula, "\n")

mod2 <- with(imp, {
  icu_type <- relevel(icu_type, ref = "MICU")
  
  glm(as.formula(formula), family = binomial)
  })
pool2 <- pool(mod2)

summary(pool2)
```

```{r}
s <- summary(pool2)
tval <- qt(0.975, df = s$df)
lower <- s$estimate - tval * s$std.error
upper <- s$estimate + tval * s$std.error

or_tab <- data.frame(
  term = s$term,
  OR = exp(s$estimate),
  LCL95 = exp(lower),
  UCL95 = exp(upper),
  p.value = s$p.value
)

or_tab
```




```{r}
# Model 0
mod0_coef <- coef(summary(mod0))
mod0_tab <- data.frame(
  term = rownames(mod0_coef),
  estimate = mod0_coef[, "Estimate"],
  std.error = mod0_coef[, "Std. Error"],
  p.value = mod0_coef[, "Pr(>|z|)"]
) |>
  filter(grepl("^icu_type", term)) |>
  mutate(
    OR = exp(estimate),
    conf.low = exp(estimate - 1.96 * std.error),
    conf.high = exp(estimate + 1.96 * std.error),
    model = "Model 0" 
) |>
  select(model, term, OR, conf.low, conf.high, p.value )

# Model 1
mod1_coef <- coef(summary(mod1))
mod1_tab <- data.frame(
  term = rownames(mod1_coef),
  estimate = mod1_coef[, "Estimate"],
  std.error = mod1_coef[, "Std. Error"],
  p.value = mod1_coef[, "Pr(>|z|)"]
) |>
  filter(grepl("^icu_type", term)) |>
  mutate(
    OR = exp(estimate),
    conf.low = exp(estimate - 1.96 * std.error),
    conf.high = exp(estimate + 1.96 * std.error),
    model = "Model 1" 
) |>
  select(model, term, OR, conf.low, conf.high, p.value )

# Model 2
s <- summary(pool2)
tval <- qt(0.975, df = s$df)
lower <- s$estimate - tval * s$std.error
upper <- s$estimate + tval * s$std.error
mod2_tab <- data.frame(
  term = s$term,
  OR = exp(s$estimate),
  conf.low = exp(lower),
  conf.high = exp(upper),
  p.value = s$p.value
) |>
  filter(grepl("^icu_type", term)) |>
  mutate(model = "Model 2")


```


```{r}
# Output table
estimate_summary <- bind_rows(mod0_tab, mod1_tab, mod2_tab) |>
  mutate(
    term = as.character(term),
    term = case_when(
      term == "icu_typeCCU"   ~ "CCU vs MICU",
      term == "icu_typeCSRU"  ~ "CSRU vs MICU",
      term == "icu_typeSICU"  ~ "SICU vs MICU",
      term == "icu_typeTSICU" ~ "TSICU vs MICU",
      TRUE ~ term
    ),
    OR = round(OR, 2),
    conf.low = round(conf.low, 2),
    conf.high = round(conf.high, 2),
    CI95 = paste0("(", conf.low, ", ", conf.high, ")"),
    p.value = ifelse(p.value < 0.001, "<0.001", round(p.value, 3))
  ) |>
  select(ICU_Type = term, Model = model, OR, CI95, p.value) 

rownames(estimate_summary) <- NULL 

estimate_summary |>
  arrange(ICU_Type, Model) |>
  kbl(
    caption = "Odds Ratios and p-values for ICU types across models",
    align = "lccccc",
    digits = 3
  ) |>
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed"),
    full_width = FALSE,
    position = "center",
    font_size = 13
  ) |>
  column_spec(1, bold = TRUE, width = "4cm") %>%
  column_spec(2, italic = TRUE, width = "4cm") %>%
  column_spec(3:4, width = "2.5cm")

```
### Q1.2.3 Model estimates
The three logistic regression models were fitted to estimate the association between ICU type and in-hospital outcome.
The estimates of the unadjusted model (Model 0) reported that CCU (OR = 0.62, CI[0.53, 0.73]), CSRU (OR = 0.19, CI[0.15, 0.24]), SICU (OR = 0.66, CI[0.57, 0.76]), and TSICU (OR = 0.49, CI[0.41, 0.58]), indicating significantly lower risk of in-hospital death (all p < 0.001) compared with MICU.
The partial-adjusted model (Model 1) adjusted for demographic factors. Slight changes appeared in OR and reported that CCU had OR = 0.50 (CI[0.43, 0.59]), CSRU had OR = 0.22 (CI[0.18, 0.28]), SICU  had OR = 0.75 (CI[0.64, 0.87]), and TSICU had OR = 0.60 (CI[0.50, 0.72]).
The fully adjusted model (Model 2) adjusted for comorbidity and severity of disease. OR in all ICU types were still less than 1 and the associations between ICU type and in-hospital outcome were still statistically significant. CSRU still reported the lowest OR of 0.20 (CI[0.15, 0.25]) and the OR value of TSICU changed most significantly, rising sharply from 0.49 in Model 0 to 0.77 (CI[0.64, 0.94]). CCU (OR = 0.66, CI[0.56, 0.79]) and SICU (OR = 0.74, CI[0.63, 0.87]) also reported with higher OR than in Model 0.

### Q1.2.4 Model diagnostics
Model diagnositics were performed on the fully adjusted model. Multicollinearity test repoted that All adjusted GVIF values of covariates were lower than 2.5, indicating no serious multicollinearity concern. The goodness-of-fit was tested through Hosmer-Lemeshow test. The tests across all 5 imputed datasets reported p-values from 0.1804 to 0.4004, with the mean p-value of 0.2628. The results suggested no evidence of lack of fit. AUC were calculated on all 5 imputed datasets and reported mean AUC of 0.818. 
Approximately 230 influential data points were identified in Cook's Distance test with threshold of 0.001, and the maximum value of Cook's distance is around 0.004. The model were refitted after removing the influential data points and the refitted model demonstrated slight differences Model 2 in OR and 95% CI.
### Q1.2.5 Sensitivity analysis
Another two models were fitted to test the reliability of the fully adjusted model.As shown in the table, the estimates of Model 3 were highly consistent with the fully adjusted model(Model 2). The OR of CCU was 0.63, that of CSRU was 0.17, that of SICU was 0.71, and that of TSICU was 0.70. All the results were statistically significant. The estimates of Model 4 presented significant differences from Model 2. The OR of CCU was 0.56, that of CSRU was 0.30, that of SICU was 0.51, and that of TSICU was 0.90. The ORs of CCU and TSICU had no statistical significance (p > 0.05). The 95% confidence intervals became wide.

#### Model diagnostics on main model

```{r}
# VIF of main model "mod2"
comp1$icu_type <- relevel(comp1$icu_type, ref = "MICU")

mod_vif <- glm(as.formula(formula), data = comp1, family = binomial)

vif_mod2 <- vif(mod_vif)
print(vif_mod2)
```


Hosmer-Lemeshow on main model "mod2"
```{r}
M <- imp$m                 
hl_pvalues <- numeric(M)   
sample_size <- 5000     


for (i in 1:M) {
  
  # Extract the data set
  data_i <- complete(imp, i)
  
  # Sampelling
  n_i <- nrow(data_i)
  if (n_i > sample_size) {
    set.seed(123 + i)  
    idx <- sample(n_i, sample_size)
    data_i_sub <- data_i[idx, ]
  } else {
    data_i_sub <- data_i
  }
  
  
  mod_i <- tryCatch(
    glm(as.formula(formula), data = data_i_sub, family = binomial),
    error = function(e) {
      cat(sprintf("The %d imputed dataset failed in fitting: %s\n", i, e$message))
      return(NULL)
    }
  )
  
  if (!is.null(mod_i)) {
    hl_i <- tryCatch(
      hoslem.test(mod_i$y, fitted(mod_i), g = 10),
      error = function(e) {
        cat(sprintf("The %d imputed failed in  H-L test: %s\n", i, e$message))
        return(NULL)
      }
    )
    
    if (!is.null(hl_i)) {
      hl_pvalues[i] <- hl_i$p.value
    } else {
      hl_pvalues[i] <- NA
    }
  } else {
    hl_pvalues[i] <- NA
  }
}

cat("---- Examine each result ----\n")
print(hl_pvalues)


valid_pvalues <- hl_pvalues[!is.na(hl_pvalues)]

cat("---- Suumary ----\n")
if (length(valid_pvalues) > 0) {
  cat(sprintf("Min p = %.4f, Max p = %.4f, Mean p = %.4f\n",
              min(valid_pvalues), max(valid_pvalues), mean(valid_pvalues)))
  cat(sprintf("Proportion of  p < 0.05 : %.2f\n", mean(valid_pvalues < 0.05)))
} else {
  cat("All test failed.\n")
}
```

AUC
```{r}
auc_values <- numeric(M)

for(i in 1:M){
  dat_i <- complete(imp,i)
  
  fit_i <- glm(as.formula(formula), data = dat_i, family=binomial)
  
  pred_i <- predict(fit_i, type = "response")
  
  roc_i <- roc(response = dat_i$death, predictor = pred_i, quiet = TRUE)
  auc_values[i] <- as.numeric(auc(roc_i))
}

print(auc_values)

valid_auc <- auc_values[!is.na(auc_values)]
cat(sprintf("Min AUC = %.3f, Max AUC = %.3f, Mean AUC = %.3f\n",
            min(valid_auc), max(valid_auc), mean(valid_auc)))

```
```{r}
fit1 <- glm(as.formula(formula), data = comp1, family = binomial)
pred1 <- predict(fit1, type = "response")
roc1 <- roc(dat1$death, pred1)

plot(roc1, col = "#4DB6AC", lwd = 2, main = "ROC Curve for Model 2 (Imputed Dataset 1)")
auc(roc1) 
```


```{r}
# Function examine cook's distance
check_cooksd <- function(model_formula, data, cutoff = 0.001) {
  mod <- glm(as.formula(model_formula), data = data, family = binomial)
  cooksd <- cooks.distance(mod)

  
  influential_points <- which(cooksd > cutoff)
  
  cat(sprintf("In dataset with n=%d samples，use the fixed threshold cutoff= %.5f\n",  nrow(data), cutoff))
  cat(sprintf("%d point \n", length(influential_points)))
  
  
  return(data.frame(ID = names(influential_points), Cooksd = cooksd[influential_points]))
}


all_influential <- list()
for (i in 1:M) {
  data_i <- complete(imp, i)
  all_influential[[i]] <- check_cooksd(formula, data_i, cutoff = 0.001)
}

```

```{r}
fit1 <- glm(as.formula(formula), data = comp1, family = binomial)
cookd <- cooks.distance(fit1)

cutoff <- 0.001

plot(1:length(cookd),
     cookd, type = "h",
     main = "Cook's Diatance (Imputed Dataset 1)",
     xlab = "Observation Index",
     ylab = "Cook's distance")
abline(h = cutoff, col = "#E57373", lty =2)

points(which(cookd > cutoff), cookd[cookd > cutoff],
       col ="#E57373", pch = 19)

```


```{r}
idx_high <- which(cookd > cutoff)

dat1 <- complete(imp, 1)

fit_full <- glm(as.formula(formula), data = dat1, family = binomial)
fit_drop <- glm(as.formula(formula), data = dat1[-idx_high, ], family = binomial)

library(broom)
or_full <- tidy(fit_full, exponentiate = TRUE, conf.int = TRUE)  |> 
  filter(grepl("^icu_type", term)) |> 
  mutate(model = "full")

or_drop <- tidy(fit_drop, exponentiate = TRUE, conf.int = TRUE)  |> 
  filter(grepl("^icu_type", term)) |> 
  mutate(model = "drop_high_cooks")


```

```{r}

compare_or <- rbind(or_full, or_drop) |>
  mutate(
    term = case_when(
      term == "icu_typeCCU"   ~ "CCU vs MICU",
      term == "icu_typeCSRU"  ~ "CSRU vs MICU",
      term == "icu_typeSICU"  ~ "SICU vs MICU",
      term == "icu_typeTSICU" ~ "TSICU vs MICU",
      TRUE ~ term),
    model = ifelse(model == "full", "Full model", "High Cook’s D removed"),
    OR = round(estimate, 2),
    CI95 = paste0("(", round(conf.low, 2), ", ", round(conf.high, 2), ")"),
    p.value = ifelse(p.value < 0.001, "<0.001", round(p.value, 3))
  ) |>
  select(ICU_Type = term, Model = model,  OR, CI95, p.value)

rownames(compare_or) <- NULL
compare_or |>
  arrange(ICU_Type, Model)|>
  kbl(
    caption = "Sensitivity Analysis: ICU Type Effects before and after removing high Cook’s D cases",
    align = "lcccc",
    digits = 3
  ) |>
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed"),
    full_width = FALSE,
    position = "center",
    font_size = 13
  ) |>
  column_spec(1, bold = TRUE, width = "4cm") |>
  column_spec(2, italic = TRUE, width = "4cm") |>
  column_spec(3:4, width = "2.5cm")
  

```

#### Sensitivity analysis model
#### Model 3： Modelling with data removed variabels with missing values over 50% and keep the complete samples
```{r}
data_low_missing <- data_analy_clean |> 
  select(-min_temp_24h, -max_temp_24h, -max_glucose_24h, -max_resp_24h, -min_sysbp_24h, -min_map_24h, -max_hr_24h, -min_spo2_24h, -max_bilirubin_24h) |>
  drop_na()

data_low_missing$icu_type <- relevel(data_low_missing$icu_type, ref = "MICU")

demographic_comorbidity <- "age_years + gender + ethnicity + admission_type + insurance + comorb_cardio + comorb_renal + comorb_pulm + comorb_diabetes + comorb_cancer + comorb_other+comorb_liver"

other_confounders <- "min_gcs_24h + min_platelets_24h + max_creatinine_24h"

formula3 <- paste("death ~ icu_type +", demographic_comorbidity, "+", other_confounders)

mod3 <- glm(as.formula(formula3), data = data_low_missing, family = binomial())

summary(mod3)

```
```{r}
exp(cbind(OR = coef(mod3), confint(mod3)))
```

#### Model 4: Modelling with samples with complete values (Keep all confounding variables)
```{r}
data_complete <- na.omit(data_analy_clean)

data_complete$icu_type <- relevel(data_complete$icu_type, ref = "MICU")

formula4 <- death ~ icu_type + age_years + gender + ethnicity + admission_type + insurance + comorb_cardio + comorb_renal + comorb_pulm + comorb_diabetes + comorb_cancer + comorb_other+comorb_liver + min_gcs_24h + min_platelets_24h + max_creatinine_24h + min_map_24h + max_hr_24h + min_spo2_24h + max_resp_24h + min_sysbp_24h + min_temp_24h + max_temp_24h + max_glucose_24h + max_bilirubin_24h   

mod4 <- glm(as.formula(formula4), data = data_complete, family = binomial())

summary(mod4)
```

```{r}
exp(cbind(OR = coef(mod4), confint(mod4)))
```
```{r}
# Model 3
mod3_coef <- coef(summary(mod3))
mod3_tab <- data.frame(
  term = rownames(mod3_coef),
  estimate = mod3_coef[, "Estimate"],
  std.error = mod3_coef[, "Std. Error"],
  p.value = mod3_coef[, "Pr(>|z|)"]
) |>
  filter(grepl("^icu_type", term)) |>
  mutate(
    OR = exp(estimate),
    conf.low = exp(estimate - 1.96 * std.error),
    conf.high = exp(estimate + 1.96 * std.error),
    model = "Model 3" 
) |>
  select(model, term, OR, conf.low, conf.high, p.value )

# Model 4
mod4_coef <- coef(summary(mod4))
mod4_tab <- data.frame(
  term = rownames(mod4_coef),
  estimate = mod4_coef[, "Estimate"],
  std.error = mod4_coef[, "Std. Error"],
  p.value = mod4_coef[, "Pr(>|z|)"]
) |>
  filter(grepl("^icu_type", term)) |>
  mutate(
    OR = exp(estimate),
    conf.low = exp(estimate - 1.96 * std.error),
    conf.high = exp(estimate + 1.96 * std.error),
    model = "Model 4" 
) |>
  select(model, term, OR, conf.low, conf.high, p.value )


```

```{r}
# Output table
sensitivity_summary <- bind_rows(mod3_tab, mod4_tab) |>
  mutate(
    term = as.character(term),
    term = case_when(
      term == "icu_typeCCU"   ~ "CCU vs MICU",
      term == "icu_typeCSRU"  ~ "CSRU vs MICU",
      term == "icu_typeSICU"  ~ "SICU vs MICU",
      term == "icu_typeTSICU" ~ "TSICU vs MICU",
      TRUE ~ term
    ),
    OR = round(OR, 2),
    conf.low = round(conf.low, 2),
    conf.high = round(conf.high, 2),
    CI95 = paste0("(", conf.low, ", ", conf.high, ")"),
    p.value = ifelse(p.value < 0.001, "<0.001", round(p.value, 3))
  ) |>
  select(ICU_Type = term, Model = model, OR, CI95, p.value) 

rownames(sensitivity_summary) <- NULL 

sensitivity_summary |>
  arrange(ICU_Type, Model) |>
  kbl(
    caption = "Odds Ratios and p-values for ICU types across sensitivity analysis models",
    align = "lccccc",
    digits = 3
  ) |>
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed"),
    full_width = FALSE,
    position = "center",
    font_size = 13
  ) |>
  column_spec(1, bold = TRUE, width = "4cm") |>
  column_spec(2, italic = TRUE, width = "4cm") |>
  column_spec(3:4, width = "2.5cm")
```

## Q1.3 Discussion


 indicating that the estimates of the model were not driven by the influential data points and the model estimates were robust and reliable.



# Question 2
## Q2.1 Methods
### Q2.1.1 Data source and cohort
The same data MIMIC-III v1.4 was used in Question 2.

MIMIC-III v1.4 contains 53423 distinct hospital admissions, and during each admission a patient could have stayed in ICU more than once. The project started with 61532 total ICU stay encounters after removing a duplicated ICU stay encounter (unique ICU stay ID = 229922).

In this question, the analysis was based on unique ICU stay encounters of adult patients rather than unique patient identifiers, which resulted in a total of 53332 unique ICU stays. ICU stays with length of stay less than 24 hours or had no length of stay data were removed, resulting in 45253 unique ICU stays. There were 198149 vital signs measurements records with in the first 24 hours, and these measurements belonged to 8972 unique ICU stays. Inner join was performed to link the vital signs to the ICU stays table, resulting the total ICU stays reduced to 6618 unique ICU stays.


### Q2.1.2 Data preprocessing
Clinical range truncation was used to clean the outliers in vital signs. For all continuous indicators, reasonable ranges were defined and any data points exceeding the ranges were clamped to the acceptable ranges. No missing values reported in demographic variables. Missing values examination reported that glucose and temperature had missing rates over 70%, heart rate, SpO$_2$, systolic blood pressure and mean arterial pressure had missing rates of 10%~20%. For each unique ICU encounter, missing time-ordered vital signs measurements were addressed using last observation carried forward and next observation carried backward imputation(Harutyunyan, 2019). A binary missingness flags were created  for each imputed vitals signs. The remained missing values after the imputation were filled with 0 and marked with missing flags to mitigate bias.

```{r}
data_filter2 <- pt_icu_outcome |>  
  
# Filter records of patients age >= 18
  filter(age_years >= 18) 
dim(data_filter2)  

# Filter ICU stays with los less than 24h
data_filter2 <- data_filter2 |>  
  filter(los >= 1) 
dim(data_filter2)

# Ensure los in ICU exist
data_filter2 <- data_filter2 |>   

  filter(!is.na(los))

dim(data_filter2)

```
```{r}
dim(vitals_hourly)
```
```{r}
# Define the reasonable ranges
hr_lower <- 20
hr_upper <- 250
resp_lower <- 5
resp_upper <- 80
sysbp_lower <- 40
sysbp_upper <- 260
map_upper <- 30
map_lower <- 160
spo2_lower <- 50
spo2_upper <- 100
temp_lower <- 30
temp_upper <- 43
glucose_lower <- 40
glucose_upper <- 600

```

```{r}
# 24h data extraction and outlier cleaning
vitals_24hr_clean <- vitals_hourly |>
  filter(hr >= 0 & hr <= 24) |>
 
  mutate(
    map_clean = case_when(
      meanarterialpressure < map_lower ~ map_lower,
      meanarterialpressure > map_upper ~ map_upper,
      TRUE ~ meanarterialpressure
    ),
    resp_clean = case_when(
      resprate < resp_lower ~ resp_lower,
      resprate > resp_upper ~ resp_upper,
      TRUE ~ resprate
    ),
    sysbp_clean = case_when(
      sysbp < sysbp_lower ~ sysbp_lower,
      sysbp > sysbp_upper ~ sysbp_upper,
      TRUE ~ sysbp
    ),
    hr_clean = case_when(
      heartrate < hr_lower ~ hr_lower,
      heartrate > hr_upper ~ hr_upper,
      TRUE ~ heartrate
    ),
    spo2_clean = case_when(
      spo2 < spo2_lower ~ spo2_lower,
      spo2 > spo2_upper ~ spo2_upper,
      TRUE ~ spo2
    ),
    temp_clean = case_when(
      temperature < temp_lower ~ temp_lower,
      temperature > temp_upper ~ temp_upper,
      TRUE ~ temperature
    ),
    glucose_clean = case_when(
      glucose < glucose_lower ~ glucose_lower,
      glucose > glucose_upper ~ glucose_upper,
      TRUE ~ glucose 
    )
  ) |>
  select(icustay_id, hr, map_clean, hr_clean, resp_clean, sysbp_clean, spo2_clean, temp_clean, glucose_clean) 
```

```{r}
dim(vitals_24hr_clean)
summary(vitals_24hr_clean)

n_unique_icustay <- n_distinct(vitals_24hr_clean$icustay_id)
n_unique_icustay
```
```{r}
####################################################
# Visualize the missing values in vital signs      #
####################################################

# Initialize a data frame
missing_vitals <- data.frame(
  variable = character(),
  na_count = numeric(),
  na_percent = character(),
  stringsAsFactors = FALSE
)

# A loop to count missing values in all variables
for (col_name in names(vitals_24hr_clean)) {
  current_col <- vitals_24hr_clean[[col_name]]
  
  count <- sum(is.na(current_col))
  
  ratio <- mean(is.na(current_col))
  
  new_row <- data.frame(
    variable = col_name,
    na_count = count,
    na_percent = scales::percent(ratio, accuracy = 0.1),
    stringsAsFactors = FALSE
  )
  
  missing_vitals <- bind_rows(missing_vitals, new_row)
}

missing_vitals <- missing_vitals %>%
  arrange(desc(na_count))

print(missing_vitals)
```


```{r}
vitals_24hr_flags <- vitals_24hr_clean|>
  mutate(
   glucose_missing_flag = is.na(glucose_clean),
   temp_missing_flag = is.na(temp_clean),
   sysbp_missing_flag = is.na(sysbp_clean),
   map_missing_flag = is.na(map_clean),
   resp_missing_flag = is.na(resp_clean),
   spo2_missing_flag = is.na(spo2_clean),
   hr_missing_flag = is.na(hr_clean)
  )

fill_cols <- c("glucose_clean", "temp_clean", "sysbp_clean", "map_clean", "resp_clean", "spo2_clean", "hr_clean") 

vitals_24hr_locf <- vitals_24hr_flags |>
  group_by(icustay_id) |>
  
  # Rank the records by time
  arrange(hr, .by_group = TRUE) |>
  
  
  fill(!!!syms(fill_cols), .direction = "down") |>
  fill(!!!syms(fill_cols), .direction = "up") |>

  mutate(
    across(all_of(fill_cols),~replace_na(., 0))
  ) |>
  
  ungroup()
```

```{r}
colSums(is.na(vitals_24hr_locf))
```


### Q2.1.2 Variable and feature engineering
The predicted LOS was defined by two classes. LOS equal to or longer than 7 days is defined as prolonged ICU stay, while LOS below 7 days was defined as non-prolonged ICU stay. Demographics and administrative including age, gender, ethnicity, insurance, admission type, ICU type and comorbidity diagnosis are used as predictors. The vital signs features were constructed with a quantiles approach (Alghatani, 2021), which emphasize the high and low quantiles of a sample to provide the model with dynamic changes of the condition. Z-score standardization was used to standardize the vital signs of each ICU stay were standardized with Z-score and interquantile thresholds (Q1 25% and Q5 75%) were calculated based on the standardized values.The vital sign observations that only belong to the Q1 and Q4 intervals were extracted from the original observations, and modified mean, modified SD and quantile percentage were calculated based on these observations. Each vital sign feature were constructed as 5 variables including original mean, original SD, modified mean, modified SD and quantile percentage.


```{r}
####################################################################################
############################  Quantile  approach ###################################
# Convert to long form
Vitals_long <- vitals_24hr_locf %>% 
  pivot_longer(
    cols = c(hr_clean, map_clean, sysbp_clean, temp_clean, glucose_clean, spo2_clean, resp_clean),
    names_to = "variable",
    values_to = "value"
  )


# Feature engineering
quantile_features <- Vitals_long |>
  group_by(icustay_id, variable) |>
  mutate(
    mean_val = mean(value, na.rm = TRUE),
    sd_val = sd(value, na.rm = TRUE)
  ) |>
  mutate(z = (value - mean_val)/sd_val) |>
  
  mutate(
    q_low = quantile(z, 0.25, na.rm = TRUE),
    q_high = quantile(z, 0.75, na.rm = TRUE)
  ) |>
  
  mutate(keep = z <= q_low | z >= q_high) |>
  
  summarise(
    n = n(),
    origin_mean = mean(value, na.rm = TRUE),
    origin_sd = ifelse(sum(!is.na(value)) > 1, sd(value, na.rm = TRUE),
                         ifelse(sum(!is.na(value)) == 1, 0, NA_real_)),
    mod_mean = ifelse(sum(keep, na.rm = TRUE) > 0,
                      mean(value[keep], na.rm = TRUE),
                      NA_real_),
    mod_sd   = ifelse(sum(keep, na.rm = TRUE) > 1,
                      sd(value[keep], na.rm = TRUE),
                      ifelse(sum(keep, na.rm = TRUE) == 1, 0, NA_real_)),
    quant_pct = ifelse(n > 0, sum(keep, na.rm = TRUE)/n, NA_real_),
    .groups = "drop"
  ) |>
  
  pivot_wider(
    names_from = variable, 
    values_from = c(origin_mean, origin_sd, mod_mean, mod_sd, quant_pct),
    names_glue = "{variable}_{.value}"
  ) |>
  
  mutate(across(
    where(is.numeric),
    function(x) ifelse(is.na(x), 1, 0),
    .names = "{.col}_missing"
  )) |>
  select(-icustay_id_missing, -n_missing)
```

```{r}
dim(quantile_features)
colSums(is.na(quantile_features))
```


```{r}
# Replace NA with 0
quantile_features_safe <- quantile_features |>
  mutate(across(everything(), ~replace_na(., 0)))
```

```{r}
dim(quantile_features_safe)
colSums(is.na(quantile_features_safe))
```
```{r}
# Link the data tables
data_merge2 <- data_filter2 |>
  
  left_join(
    icustays |> select(icustay_id, first_careunit),
    by = "icustay_id"
  ) |>
  mutate(
    icu_type = as.factor(first_careunit)
  ) |>
  
  left_join(
    patients |> select(subject_id, gender),
    by = "subject_id"
  ) |>
  
  left_join(
    admissions |> select(hadm_id, admission_type, insurance, ethnicity),
    by = "hadm_id"
  ) |>
  
  mutate(
    # Binary indicator of length of stay
    prolonged_los = factor(ifelse(los >= 7, 1,0),
                           levels = c(0,1),
                           labels = c("short stay", "prolonged stay")),
    gender = as.factor(gender),               
    insurance = as.factor(insurance),         
    ethnicity = as.factor(ethnicity),         
    admission_type = as.factor(admission_type),
    first_careunit = as.factor(first_careunit),
    
    # Recode the ethnicity
    ethnicity = case_when(
      str_detect(ethnicity, "WHITE") ~ "WHITE",
      str_detect(ethnicity, "BLACK|AFRICAN AMERICAN") ~ "BLACK",
      str_detect(ethnicity, "HISPANIC|LATINO") ~ "HISPANIC",
      TRUE ~ "OTHER/UNKNOWN"
    ),
    ethnicity = as.factor(ethnicity)
  ) |>
  select(subject_id, hadm_id, icustay_id, age_years, gender, icu_type, admission_type, insurance, ethnicity, prolonged_los)|>
  
  left_join(
    comorbidity_groups, by = "hadm_id"
  )

dim(data_merge2)
```

```{r}
summary(data_merge2)
```

```{r}
# Merge with demographics and comorbidty data
data_analysis <- data_merge2 |>
  
  inner_join(
    quantile_features_safe,
    by = "icustay_id"
  ) |>
  select(-n)


```

```{r}
dim(data_analysis)

colSums(is.na(data_analysis))
```
```{r}
###################################################################################
############################### Demographic results ###############################
demo_vars <- c("age_years", "gender", "icu_type", "admission_type", "insurance", "ethnicity", "comorb_cardio", "comorb_renal", "comorb_pulm", "comorb_diabetes", "comorb_cancer", "comorb_liver", "comorb_other", "prolonged_los")

data_analysis |>
  select(all_of(demo_vars)) |>
  mutate(
    across(starts_with("comorb_"), ~factor(.x, levels = c("0","1"), labels = c("No","Yes")))
  ) |>
  tbl_summary(
    statistic = list(
      all_continuous() ~ "{mean} ({sd})",
      all_categorical() ~ "{n} ({p}%)"
    ),
    digits = list(
      all_continuous() ~ 1, 
      all_categorical() ~ 1
    ),
    missing = "ifany",
    label = list(
      age_years ~ "Age (years)",
      gender ~ "Gender",
      admission_type ~ "Admission Type", 
      insurance ~ "Insurance",
      ethnicity ~ "Ethnicity",
      icu_type ~ "ICU Type",
      comorb_cardio ~ "Cardiovascular Comorbidity", 
      comorb_renal ~ "Renal Comorbidity",
      comorb_pulm ~ "Pulmonary Comorbidity", 
      comorb_diabetes ~ "Diabetes", 
      comorb_cancer ~ "Cancer", 
      comorb_liver ~ "Liver Disease", 
      comorb_other ~ "Other Comorbidity",
      prolonged_los ~ "Prolonged Length of Stay in ICU"
    )
  ) |>
  modify_header(label = "**Variable**") |>
  bold_labels()
```

```{r}
#############################################################################
###################### Final Preparation for ML##############################
data_ml_ready <- data_analysis|>
   mutate(
    prolonged_los = ifelse(prolonged_los == "prolonged stay", 1, 0)
  ) |>
  # One-hot coding
  fastDummies::dummy_cols(
  remove_first_dummy = TRUE, 
  remove_selected_columns = TRUE
)
```

```{r}
dim(data_ml_ready)
str(data_ml_ready)
```
```{r}

# Set random seed
set.seed(42)
ids <- unique(data_ml_ready$subject_id)
train_ids <- sample(ids, size = floor(0.8 * length(ids)))
train_idx <- data_ml_ready$subject_id %in% train_ids

train_data <- data_ml_ready[train_idx, ]
test_data <- data_ml_ready[!train_idx, ]

# Remove all ID columns
train_data <- train_data |> select(-subject_id, -hadm_id, -icustay_id)
test_data <- test_data |> select(-subject_id, -hadm_id, -icustay_id)


# ----------------Data preparation for LR baseline------------
x_train <- as.matrix(train_data |> select(-prolonged_los))
x_test  <- as.matrix(test_data  |> select(-prolonged_los))
y_train <- train_data$prolonged_los
y_test  <- test_data$prolonged_los


```

```{r}
# -----------------Data preparation for XGB model----------
# Create DMatrix
y_train <- as.numeric(as.character(train_data$prolonged_los))
y_test <- as.numeric(as.character(test_data$prolonged_los))

dtrain <- xgboost::xgb.DMatrix(
  data = as.matrix(train_data |> select(-prolonged_los)), 
  label = y_train
)

dtest <- xgboost::xgb.DMatrix(
  data = as.matrix(test_data |> select(-prolonged_los)), 
  label = y_test
)
```

### Q2.1.3 Model selection and application
The dataset was split into 80% training set and 20% test set. The split was performed according to unique patients subject ID to ensure that data belonging to one patient do not appear in both training set and test set. The models were trained using the training set and tested the performance using the unseen testing set.
Logistic regression and extreme gradient boosting (XGBoost) machine learning algorithms were used for the binary classification model. To avoid overfitting, 10-fold cross-validation was used on the training set. Logistic regression model was fitted as a baseline model, and LASSO was used to avoid overfitting. XGBoost is an extension of the gradient boosting of gradient boosting algorithm, which combines weak learners sequentially (Chen, 2016; Wiens, 2025). XGBoost is capable of capturing  more complex  nonlinear relationships and feature interactions than traditional linear models. A baseline XGBoost model was fitted and then fine-tuned through grid search to improve the ability of generalization. The hyperparameters for parameter tuning include：
Learning Rate: The step size shrinkage used to prevent overfitting. Learning rate was explored among 0.01, 0.03 and 0.05.
Maximun Depth: The maximum depth of a tree. Values were considered from 2 to 5.
Gamma: The minimum loss reduction required to make a further partition on a leaf node. Values from 0 to 5.
Subsample ratio of training instances (subsample): Fixed to 0.7.
Subsample ratio of features (colsample_bytree): Fixed to 0.7.
Weight for positive class (scale_pos_weight): Calculate by Negative class/Positive class.
Minimum sum of instance weight (hessian) needed in a child (min_child_weight): Explored among 5 and 6.

### Q2.1.4 Model evaluation
To evaluate the models performance on training and test set, the metrics evaluated include: AUROC, accuracy, sensitivity, specificity, PPV, NPV. The 95% confidence intervals were also calculated.
## Q2.2 Results

### Q2.2.1 Descriptive statistics of cohort
Totally 6,618 ICU stays were included in the analysis, among which there are 1066 prolonged ICU stays (16.1%). The overall age mean of the patients was 63.8 (16.8). The proportion of male patients is higher, at 56.1%. The study population was mainly white, accounting for 71.6%. Most of the patients (82.5%) were admitted to the hospital through emergency. Most patients payed through  Medicare (55.7%) or private (31.7%) insurance. The Medical Intensive Care Unit (MICU) is the most common type of ICU, admitting 38.4% of patients. Other major types include cardiothoracic surgery recovery units (CSRUs), surgical intensive care units (SICUs), and coronary care units (CCUs). Cardiovascular comorbidity is the most common in CCU (59.2%), while the proportion pulmonary comorbidity reached 54.8%. 


### Q2.2.2 Binary Classification model results
Table X shows the performance of the binary classifications models. LR model XGB baseline model demonstrated the very closed accuracy of 0.832 and 0.830, while fine-tuned XGB models only has accuracy of 0.715. In. terms of sensitivity and specificity, LR and XGB baseline models has higher specificity values of 0.994 and 0.991, while the sensitivity values are 0.018 and 0.023. Fine-tuned XGB model showed sensitivity and specificity of 0.534 and 0.752, indicating significantly improved ability to predict positive categories. All models have acceptable performance on NPV, among which fine-tuned XGB model the highest NPV of 0.890. The PPV of the LR and XGB (Baseline) models is relatively low (0.364 and 0.333, respectively), while fine_tuned XGB model has PPV of 0.300.
Table X demonstrate the AUROC of both training and test set of three models. Baseline XBG model achieved the highest AUROC on the training set, but the AUROC on the test set was only 0.678, indicating a rather serious overfitting. The fine-tuned XGB model showed an AUROC of the training set decreased to 0.818, but the AUROC of the test set increased o.681, indicating an improvement in the generaliaztion. The AUROC of the LR test set was 0.658, which was the lowest among the three models.

```{r}
#################################################################################
######################## Baseline Logistic Regression Model######################
set.seed(42)
LR_lasso_mod <- cv.glmnet(
  x = x_train,
  y = y_train,
  family = "binomial",
  alpha = 1,
  nfolds = 10,
  type.measure = "auc"
)
```

```{r}
plot(LR_lasso_mod)

LR_lasso_mod$lambd.min
LR_lasso_mod$lambd.1se
```

```{r}
pred_lr <- predict(
  LR_lasso_mod,
  newx = x_test,
  s = "lambda.min",
  type = "response"
)

head(pred_lr)
```
```{r}
# Train AUC
pred_lr_train <- predict(LR_lasso_mod, newx = x_train, s="lambda.min", type="response")
roc_lr_train <- roc(y_train, pred_lr_train)
auc_train_lr <- auc(roc_lr_train)

# Test AUC
roc_lr_test <- roc(y_test, pred_lr)
auc_test_lr <- auc(roc_lr_test)

cat("Training set AUC:", auc_train_lr, "\n")
cat("Testing set AUC:", auc_test_lr, "\n")
```


https://xgboost.readthedocs.io/en/stable/R-package/xgboost_introduction.html#introduction
```{r}
#################################################################################
########################### Baseline XGB Model###################################
basic_params <- list(
    objective = "binary:logistic",
    eval_metric = "auc",
    max_depth = 5,
    eta = 0.1,
    subsample = 0.8,
    colsample_bytree = 0.8,
    min_child_weight = 2
)
```


```{r}
xgb_basic <- xgb.train(
  params = basic_params,
  data = dtrain,
  nrounds = 200,
  watchlist = list(train = dtrain, test = dtest),
  early_stopping_rounds = 20,
  print_every_n = 20
)
```

```{r}
# Simple evaluation of the baseline model
pred_basic <- predict(xgb_basic, dtest)
roc_basic <- roc(test_data$prolonged_los, pred_basic)
auc_basic <- auc(roc_basic)
cat("Baseline Test AUC:", auc_basic, "\n")
```

```{r}
#################################################################################
##############################Fine-tuning########################################
# Define parameters
param_grid <- expand.grid(
  max_depth = c(3L,4L, 5L),
  eta = c(0.01,0.03, 0.05),
  subsample = c(0.7),
  colsample_bytree = c(0.7),
  min_child_weight = c(5,6),
  gamma = c(0, 1, 2, 3, 4, 5),
  KEEP.OUT.ATTRS = FALSE
)
```

```{r}
positive <- sum(train_data$prolonged_los == 1)
negative <- sum(train_data$prolonged_los == 0)
scale_pos_weight <- negative/positive
scale_pos_weight
```

```{r}
best_auc <- 0
best_params <- list()

for (i in 1:nrow(param_grid)){
  params <- list(
    objective = "binary:logistic",
    eval_metric = c("auc", "logloss"),
    max_depth = param_grid$max_depth[i],
    eta = param_grid$eta[i],
    subsample = param_grid$subsample[i],
    colsample_bytree = param_grid$colsample_bytree[i],
    min_child_weight = param_grid$min_child_weight[i],
    scale_pos_weight = scale_pos_weight,
    gamma = param_grid$gamma[i]
    
  )
  
  cat("\nRunning CV", i, "of", nrow(param_grid), "\n")
  
  cv_result <- xgb.cv(
    params = params,
    data = dtrain,
    nrounds = 1000,
    nfold = 10,
    metrics = c("auc", "logloss"),
    early_stopping_rounds = 20,
    verbose = FALSE
  )
  
  best_iter <- cv_result$best_iteration
  mean_auc <- max(cv_result$evaluation_log$test_auc_mean)
  
  if (mean_auc > best_auc){
    best_auc <- mean_auc
    best_params <- params
    best_nrounds <- best_iter
    }
}

cat("\nBest AUC:", best_auc, "\n")
print(best_params)
cat("Best nround:", best_nrounds,"\n")
```

Use the best parameters to train the model
```{r}
xgb_best <- xgb.train(
  params = best_params,
  data = dtrain,
  nrounds = best_nrounds,
  watchlist = list(train = dtrain, test = dtest),
  early_stopping_rounds = 20,
  print_every_n = 20
)
```

```{r}
pred_prob <- predict(xgb_best, dtest)
pred_class <- ifelse(pred_prob >= 0.5, 1, 0)
truth <- test_data$prolonged_los

confusionMatrix(factor(pred_class), factor(truth), positive = "1")
roc_obj <- roc(truth, pred_prob)
plot(roc_obj, col = "lightblue")
auc(roc_obj)
```



```{r}
###################################################################################
##########################        AUROC      ######################################
###################################################################################
auc_calculate <- function(model_name, y_train, y_train_prob, y_test, y_test_prob){
  
  # Training set ROC
  roc_train <- roc(y_train, y_train_prob, quiet = TRUE)
  auc_train <- as.numeric(auc(roc_train))
  auc_train_ci <- as.numeric(ci.auc(roc_train))
  
  # Testing set ROC
  roc_test <- roc(y_test, y_test_prob, quiet = TRUE)
  auc_test <- as.numeric(auc(roc_test))
  auc_test_ci <- as.numeric(ci.auc(roc_test))
  
  tibble(
    Model = model_name,
    
    `Train AUROC` = sprintf("%.3f (%.3f–%.3f)", auc_train, auc_train_ci[1], auc_train_ci[3]),
    `Test AUROC`  = sprintf("%.3f (%.3f–%.3f)", auc_test,  auc_train_ci[1],  auc_train_ci[3])
  )
}
```

```{r}
# LR baseline AUC
auc_lr <- auc_calculate(
  "LR",
  y_train = y_train,
  y_train_prob = as.numeric(pred_lr_train),
  y_test = y_test,
  y_test_prob = as.numeric(pred_lr)
)
```

```{r}
# XGB baseline AUC
pred_basic_train <- predict(xgb_basic, dtrain)
pred_basic <- predict(xgb_basic, dtest)
auc_xgb_basic <- auc_calculate(
  "XGB (Baseline)",
  y_train = y_train,
  y_train_prob = pred_basic_train,
  y_test = truth,
  y_test_prob = pred_basic
)
```


```{r}
# XGB fine-tuned AUC
pred_prob_train <- predict(xgb_best, dtrain)
pred_prob <- predict(xgb_best, dtest)
auc_xgb_best <- auc_calculate(
  "XGB (fine-tuned)",
  y_train = y_train,
  y_train_prob = pred_prob_train,
  y_test = truth,
  y_test_prob = pred_prob
)
```

```{r}
auc_table <-  bind_rows(
  auc_lr,
  auc_xgb_basic,
  auc_xgb_best
)

auc_table_report <- auc_table %>%
  gt::gt() |>
  gt::tab_header(
    title = gt::md("**AUROC Performance Summary**")
  ) |>
  gt::cols_label(
    Model = "Model",
    `Train AUROC` = "Train AUROC(95%CI)",
    `Test AUROC` = "Test AUROC(95%CI)"
  ) |>
  gt::fmt_markdown(everything())

auc_table_report
```





```{r}
###################################################################################
##########################       Model Performance     ############################
###################################################################################
performance_calculate <- function(model_name, y_true, y_prob, threshold = 0.5){
  
  y_true <- as.numeric(y_true)
  y_pred <- ifelse(y_prob >= threshold, 1, 0)
  
  # Confusion matrix
  TP <- sum(y_pred == 1 & y_true == 1)
  TN <- sum(y_pred == 0 & y_true == 0)
  FP <- sum(y_pred == 1 & y_true == 0)
  FN <- sum(y_pred == 0 & y_true == 1)
  
  # CI
  ci_binom <- function(successes, total){
    if(total == 0) return(c(NA, NA))
    out <- binom.test(successes, total)$conf.int
    return(round(out, 3))
  }
  
  # Metrics
  accuracy     <- (TP + TN) / (TP + TN + FP + FN)
  sensitivity  <- TP / (TP + FN)
  specificity  <- TN / (TN + FP)
  ppv          <- TP / (TP + FP)
  npv          <- TN / (TN + FN)
  
  accuracy_CI    <- ci_binom(TP + TN, TP + TN + FP + FN)
  sensitivity_CI <- ci_binom(TP, TP + FN)
  specificity_CI <- ci_binom(TN, TN + FP)
  ppv_CI         <- ci_binom(TP, TP + FP)
  npv_CI         <- ci_binom(TN, TN + FN)
  
  combine_ci <- function(value, ci){
    paste0(
      round(value, 3),
      " (",
      ci[1], "–", ci[2],
      ")"
    )
  }
  
  tibble(
    Model = model_name,
    `Accuracy(95% CI)` = combine_ci(accuracy, accuracy_CI),
    `Sensitivity(95% CI)` = combine_ci(sensitivity, sensitivity_CI),
    `Specificity(95% CI)` = combine_ci(specificity, specificity_CI),
    `PPV(95% CI)` = combine_ci(ppv, ppv_CI),
    `NPV(95% CI)` = combine_ci(npv, npv_CI)
  )
}

```


```{r}
results_lr <- performance_calculate(
  model_name = "LR",
  y_true = y_test,
  y_prob = as.numeric(pred_lr)
)



results_xgb_baseline <- performance_calculate(
  model_name = "XGB(Baseline)",
  y_true = y_test,
  y_prob = pred_basic
)

results_xgb_ft <- performance_calculate(
  model_name = "XGB(Fine-tuned)",
  y_true = y_test,
  y_prob = pred_prob
)

final_performance <- bind_rows(results_lr, results_xgb_baseline, results_xgb_ft)

final_performance_report <- final_performance |>
  gt::gt() |>
  gt::tab_header(
    title = gt::md("**Model Performance Summary**")
  )|>
  gt::fmt_markdown(everything())

final_performance_report
```


```{r}
calibration_data <- function(prob, truth, n_bins = 10){

  # 转成 numeric，避免 factor/NULL 导致崩溃
  prob  <- as.numeric(prob)
  truth <- as.numeric(truth)

  # 检查输入
  if(length(prob) != length(truth)){
    stop("prob and truth must have same length")
  }
  if(any(is.na(prob))){
    warning("NA values detected in prob, removing...")
    keep <- !is.na(prob)
    prob  <- prob[keep]
    truth <- truth[keep]
  }

  # 手动分箱（比 ntile 更稳）
  bins <- cut(
    prob,
    breaks = quantile(prob, probs = seq(0, 1, length.out = n_bins + 1), na.rm = TRUE),
    include.lowest = TRUE
  )

  df <- data.frame(
    prob = prob,
    truth = truth,
    bin = bins
  )

  calib <- df %>%
    group_by(bin) %>%
    summarise(
      mean_pred = mean(prob),
      mean_obs  = mean(truth),
      n = n(),
      .groups = "drop"
    )

  return(calib)
}

cal_lr   <- calibration_data(pred_lr, truth)
cal_base <- calibration_data(pred_basic, truth)
cal_tune <- calibration_data(pred_prob, truth)

```

```{r}
cal_lr$model   <- "Logistic Regression"
cal_base$model <- "XGB (Baseline)"
cal_tune$model <- "XGB (Fine-tuned)"

cal_all <- bind_rows(cal_lr, cal_base, cal_tune)

ggplot(cal_all, aes(x = mean_pred, y = mean_obs, color = model)) +
  geom_line(linewidth = 1) +
  geom_point(size = 2) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed") +
  scale_color_manual(values = c(
    "Logistic Regression" = "#1f77b4",
    "XGB (Baseline)" = "#ff7f0e",
    "XGB (Fine-tuned)" = "#2ca02c"
  )) +
  labs(
    title = "Calibration Curves for Three Models",
    x = "Mean Predicted Probability",
    y = "Observed Proportion"
  ) +
  theme_bw(base_size = 14) +
  theme(
    legend.title = element_blank(),
    plot.title = element_text(hjust = 0.5)
  )

```




```{r}
X_train <- as.matrix(train_data %>% select(-prolonged_los))
```

```{r}
# Top 20 SHAP importance
shap_imp <- shap_long |>
  group_by(variable) |>
  summarise(mean_abs_shap = mean(abs(value))) |>
  arrange(desc(mean_abs_shap)) |>
  head(20)

# Plot the importance
ggplot(shap_imp, aes(x = reorder(variable, mean_abs_shap), 
                      y = mean_abs_shap)) +
  geom_col(fill = "gray") +
  coord_flip() +
  labs(title = "Top 20 Features by Mean Absolute SHAP Value",
       x = "Feature",
       y = "Mean |SHAP value|") +
  theme_minimal()
```



### Q2.3 Discussion

