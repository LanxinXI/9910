---
title: "DEA and data cleaning"
author: "LANXIN XI"
date: "`r Sys.Date()`"
output: word_document
---
# Introduction

Providing care to critical patients, intensive care units (ICU) are one of the departments where care work is most demanded and the medical resources are most concentrated [1]. Patient outcomes have always been concerned, especially in-hospital mortality and length of stay, as important evidence for optimizing medical resources allocation and improving care efficiency. 
Previous studies led to the suggestion that different disciplinary ICUs presents differences in in-hospital mortality. A study by Afessa et al. [2] reported different in-hospital mortality in medical ICU, surgical ICU and mixed ICU according to the analysis on APACHE III database. Park et al. [3] reported interesting outcomes that surgical ICU patients are less likely to die than the medical ICU patients even though the higher likelihood of experiencing more harm.
The length of stay (LOS) in ICU is associated with care burden [4], prolonged ICU stay results in higher care costs and medical resources utilization[1]. It has been reported that various clinical indicators and patients demographics are associated with LOS[5]. Open source datasets and prospectively collected data have been used to predict ICU LOS [6-8] and present that the prediction of ICU LOS and long-term hospitalization risk is effective.
This project focused on two research questions: i) the association between the ICU type of the first ICU stay and adult patient in-hospital mortality outcome; ii) the prediction of the prolonged ICU stays (≥7 day) of adult patient with patient demographics and ICU bedside measurements in the first 24 hours in ICU.

The objectives of this project are to : i) estimate the total effect of ICU type of the first ICU stay on the  adult patients in-hospital mortality outcomes; ii)predict the risk of adult patients' prolonged ICU stays (≥7 day) with ICU bedside measurements in the first 24 hours in ICU.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)
library(readr)
library(janitor)
library(patchwork)
library(naniar)
library(forcats)
library(comorbidity)
library(scales)
library(mice)
library(ggcorrplot)
library(ggpubr)
library(lme4)
library(pROC)
library(ResourceSelection)
library(lmtest)
library(rms)
library(rmda)
library(car)
library(fastDummies)
library(xgboost)
library(rsample)
library(caret)
library(gtsummary)
library(broom)
library(kableExtra)
```



```{r Data loading, echo=FALSE}
###############################################################################
###################### Data loading and preparation ###########################
###############################################################################
admissions <- readr::read_csv("../data/mimic_data/admissions.csv")
patients <- readr::read_csv("../data/mimic_data/patients.csv")
icustays <- readr::read_csv("../data/mimic_data/icustays.csv")
pt_icu_outcome <- readr::read_csv("../data/mimic_data/pt_icu_outcome.csv")
transfers <- readr::read_csv("../data/mimic_data/transfers.csv")
vitals_hourly <- readr::read_csv("../data/mimic_data/vitals_hourly.csv")
gcs_hourly <- readr::read_csv("../data/mimic_data/gcs_hourly.csv")
pv_mechvent <- readr::read_csv("../data/mimic_data/pv_mechvent.csv")
labs_hourly <- readr::read_csv("../data/mimic_data/labs_hourly.csv")
output_hourly <- readr::read_csv("../data/mimic_data/output_hourly.csv")
icd9_diag <- readr::read_csv("../data/mimic_data/icd9_diag.csv")

```
```{r}
dim(pt_icu_outcome)
```

```{r}
# Check the duplicate ICU stay `229922`
duplicated_patient <- pt_icu_outcome %>%
  filter(icustay_id == 229922)
print(duplicated_patient)

duplicated_t <- labs_hourly %>%
  filter(icustay_id == 229922)
print(duplicated_t)
```

```{r}
# Remove the duplicated record
pt_icu_outcome <- pt_icu_outcome %>%
  filter(!(icustay_id == 229922 & admittime == as.POSIXct("2185-12-02 23:53:00", tz = "UTC")))

duplicated_patient_cleaned <- pt_icu_outcome %>%
  filter(icustay_id == 229922)
print(duplicated_patient_cleaned)
```

```{r}
dim(pt_icu_outcome)
summary(pt_icu_outcome)
```

# Question 1

## Q1.1 Methods
### Q1.1.1 Data source and cohort

MIMIC-III v1.4 [9] (Medical Information Mart for Intensive Care III) is the data set used in this project，which is a large, freely-available database comprising health related data associated with patients who stayed within ICUs of the Beth Israel Deaconess Medical Center during the period 2001-2012.
The data contains 53423 distinct hospital admissions, and during each admission a patient could have stayed in ICU more than once. The project start with 61532 total ICU stay encounters after removing a duplicated ICU stay encounter (unique ICU stay ID = 229922).
In this question, the analysis was based on unique adult patient's first ICU stay encounter among the patient's all ICU encounters, which resulted in a total of 38509 unique ICU stay. The admissions without clear hospital outcome are also remove, resulting in 32,245 unique ICU stay.

```{r Link the main data tables}
###############################################################################
###################### Data preprocessing and EDA ###########################
###############################################################################
# Retain the first ICU records of each patient's all ICU records

data_filter <- pt_icu_outcome |>  
  
  group_by(subject_id) |>
  slice_min(intime, n =1, with_ties = FALSE) |>
  ungroup()
dim(data_filter)

# Filter records of patients age >= 18
data_filter <- data_filter |>
  filter(age_years >= 18)

dim(data_filter)

# Ensure exist of hospital outcome
data_filter <- data_filter |>   

  filter(!is.na(hospital_expire_flag))

dim(data_filter)




data_merge <- data_filter |>
  # Link the data tables with demographic information data
  left_join(
    icustays |> select(icustay_id, first_careunit),
    by = "icustay_id"
  ) |>
  mutate(
    icu_type = as.factor(first_careunit)
  ) |>
  
  left_join(
    patients |> select(subject_id, gender),
    by = "subject_id"
  ) |>
  
  left_join(
    admissions |> select(hadm_id, admission_type, insurance, ethnicity),
    by = "hadm_id"
  ) |>
  mutate(
    death = as.factor(hospital_expire_flag), 
    gender = as.factor(gender),               
    insurance = as.factor(insurance),         
    ethnicity = as.factor(ethnicity),         
    admission_type = as.factor(admission_type)
  )

```


### Q1.1.2 Variables

The outcome in this question was define as the in hospital outcome and the exposure ICU type was defined as the first care unit in one unique ICU stay encounter, including Cardiac Care Unit(CCU), Cardiac Surgery Unit(CSRC), Medical Intensive Care Unit(MICU), Neuro Intensive Care Unit(NICU), Surgical Intensive Care Unit(SICU) and Trauma Surgical Intensive Care Unit (TSICU). To estimate the total effect of ICU type on the in-hospital mortality outcome, the potential confounders will be controlled while the potential intermediate variables were avoided to be controlled (Greenland, 1999). Besides the important demographics (e.g. age, gender, ethnicity) and administrative (e.g. admission type, insurance), the variable selection of potential confoundings is based on SOFA/APACHE indicators. SOFA and APACHE are widely used in predicting  mortality of patients in different subspecialties, especially in ICU (Shahi, 2024; Moreno, 2023). SOFA consists of indicators cover six main systems of respiratory, coagulation, hepatic, cardiovascular, central nervous and renal system, while APACHE also emphasis vital signs and gastric chronic diseases (Vincent, 1996; Knaus, 1985).  According to the temporal sequence principle (Baker,2014), confounding factors must be measured before or simultaneously with exposure, only the vital signs and lab measurements collected within the first 24 hours after patients were enrolled to ICU were used. The extreme values that can best reflect the severity of the patient's condition were created as the representative value with in the 24h time window. Table 1 summarizes all the covariates that will be considered. The vital signs include heart rate, O2 saturation pulse oxymetry, respiratory rate, systolic blood pressure, mean arterial pressure, body temperature, Glasgow Coma Scales (GCS) and glucose. Laboratory measurements include creatinine, platelets and bilirubin.

插入表格图片


#### GCS 
The minimum with 24 hr
```{r gcs}

summary(gcs_hourly)

gcs_24hr_min <- gcs_hourly |>
  filter(hr >= 0 & hr <= 24) |>  # Filter gcs score within 24hr
  group_by(icustay_id) |>
  summarise(
    min_gcs_24h = min(gcs, na.rm = TRUE) # Extract the minimum gcs within 24hr
  ) |>
  ungroup()

```
#### Bedside measurements
```{r}
vital_24hr <- vitals_hourly |>
  filter(hr >= 0 & hr <= 24) |>
  group_by(icustay_id) |>
  summarise(
    min_map_24h = min(meanarterialpressure, na.rm = TRUE),
    min_sysbp_24h = min(sysbp, na.rm = TRUE),
    max_hr_24h = max(heartrate, na.rm = TRUE),
    max_resp_24h = max(resprate, na.rm = TRUE),
    min_temp_24h = min(temperature, na.rm = TRUE),
    max_temp_24h = max(temperature, na.rm = TRUE),
    max_glucose_24h = min(glucose, na.rm = TRUE),
    min_spo2_24h = min(spo2, na.rm = TRUE),
    
  ) |>
  ungroup()

summary(vital_24hr)
summary(vitals_hourly)

```
#### lab measurements
```{r}
lab_24hr <- labs_hourly |>
  filter(hr >= -24 & hr <= 24 ) |>
  group_by(icustay_id) |>
  summarise(
    max_creatinine_24h = max(creatinine, na.rm = TRUE),
    min_platelets_24h = min(platelets, na.rm = TRUE),
    max_bilirubin_24h = max(bilirubin, na.rm = TRUE)
  )

summary(labs_hourly)
```
#### Comorbidity
```{r}
icd9_diag <- as.data.frame(icd9_diag)
icd9_diag$hadm_id <- as.character(icd9_diag$hadm_id)
icd9_diag$icd9_code <- gsub("\\.", "", icd9_diag$icd9_code) 
icd9_diag$icd9_code <- as.character(icd9_diag$icd9_code)
icd9_for_comorb <- icd9_diag[grepl("^[0-9]", icd9_diag$icd9_code), ]
```

```{r}
elixhauser <- comorbidity(
  x = icd9_for_comorb,
  id = "hadm_id",
  code = "icd9_code",
  map = "elixhauser_icd9_quan",
  assign0 = TRUE
)

```

```{r}
comorbidity_groups <- elixhauser %>%
  mutate(
    comorb_cardio = as.integer(chf == 1 | carit == 1 | valv == 1 | pcd == 1 | pvd == 1),
    comorb_renal = as.integer(rf == 1),
    comorb_pulm = as.integer(hypunc == 1 | hypc == 1), 
    comorb_diabetes = as.integer(diabunc == 1 | diabc == 1),
    comorb_cancer = as.integer(solidtum == 1 | metacanc == 1 | lymph == 1),
    comorb_liver = as.integer(ld == 1),
    comorb_other = as.integer(aids == 1 | rheumd == 1)
  ) %>%
  select(hadm_id, comorb_cardio, comorb_renal, comorb_pulm, comorb_diabetes, comorb_cancer, comorb_liver, comorb_other)

comorbidity_groups$hadm_id = as.numeric(comorbidity_groups$hadm_id)
comorbidity_groups$comorb_cardio = as.factor(comorbidity_groups$comorb_cardio)
comorbidity_groups$comorb_renal = as.factor(comorbidity_groups$comorb_renal)
comorbidity_groups$comorb_pulm = as.factor(comorbidity_groups$comorb_pulm)
comorbidity_groups$comorb_diabetes = as.factor(comorbidity_groups$comorb_diabetes)
comorbidity_groups$comorb_cancer = as.factor(comorbidity_groups$comorb_cancer)
comorbidity_groups$comorb_liver = as.factor(comorbidity_groups$comorb_liver)
comorbidity_groups$comorb_other = as.factor(comorbidity_groups$comorb_other)

head(comorbidity_groups)

```

#### Merge the confounder variabels to the main dataframe
```{r Create the analysis dataframe for Question 1}
# Select useful variables from the "data_merge"
data_analysis <- data_merge |>
  select(subject_id, hadm_id, icustay_id, age_years, gender, icu_type, admission_type, insurance, ethnicity, death) |>
  # Add the confounder variables to the dataframe
  left_join(gcs_24hr_min, by = "icustay_id") |>
  left_join(vital_24hr, by = "icustay_id") |>
  left_join(lab_24hr, by = "icustay_id") |>
  left_join(comorbidity_groups, by = "hadm_id") |>
  mutate(
    # Recode the ethnicity
    ethnicity = case_when(
      str_detect(ethnicity, "WHITE") ~ "WHITE",
      str_detect(ethnicity, "BLACK|AFRICAN AMERICAN") ~ "BLACK",
      str_detect(ethnicity, "HISPANIC|LATINO") ~ "HISPANIC",
      TRUE ~ "OTHER/UNKNOWN"
    ),
    ethnicity = as.factor(ethnicity)
  )
```

 

```{r}
###############################################################################
###################### EDA and further preprocessing ###########################
###############################################################################
# Sanity check
dim(data_analysis)
str(data_analysis)
summary(data_analysis)
```

#### Check missing values
```{r Visualize the missing values}
####################################################
#            Visualize the missing values          #
####################################################

# Initialize a data frame
missing_report_final <- data.frame(
  variable = character(),
  na_count = numeric(),
  na_percent = character(),
  stringsAsFactors = FALSE
)

# A loop to count missing values in all variables
for (col_name in names(data_analysis)) {
  current_col <- data_analysis[[col_name]]
  
  count <- sum(is.na(current_col))
  
  ratio <- mean(is.na(current_col))
  
  new_row <- data.frame(
    variable = col_name,
    na_count = count,
    na_percent = scales::percent(ratio, accuracy = 0.1),
    stringsAsFactors = FALSE
  )
  
  missing_report_final <- bind_rows(missing_report_final, new_row)
}

missing_report_final <- missing_report_final %>%
  arrange(desc(na_count))

print(missing_report_final)
```

#### Check the distribution of all variables
```{r}
#################################################
# Check the distribution of continuous variables#
#################################################
con_vars <- c("age_years", "min_gcs_24h", "min_map_24h", "min_sysbp_24h",
              "max_hr_24h", "max_resp_24h", "min_temp_24h", "max_temp_24h", 
              "max_glucose_24h", "min_spo2_24h", "max_creatinine_24h", "min_platelets_24h",
              "max_bilirubin_24h" )

for (var in  con_vars){
  plot_data <- data_analysis |>
    filter(!is.na(!!sym(var)))
  
  if (nrow(plot_data) > 10) {
    p <- ggplot(plot_data, aes(x =!!sym(var))) +
      geom_histogram(aes(y = after_stat(density)), bins = 30, fill = "#0072B2", alpha = 0.7) +
      geom_density(color = "orange", linewidth = 1) +
      labs(
        title = paste("Distribution:", var, "(No NA)"),
        subtitle = paste("Observations:", nrow(plot_data)),
        x = var, 
        y = "Density"
      ) +
      theme_minimal()
    
    print(p)
  } else
    cat(paste(var, "has no more than 10 observations with values."))
}
```


```{r}
#################################################
# Check the distribution of categorical variables#
#################################################
cat_vars <- c("icu_type", "gender", "admission_type", "insurance", "ethnicity", 
              "death", "comorb_cardio", "comorb_renal", 
              "comorb_pulm", "comorb_diabetes", "comorb_cancer", "comorb_liver", 
              "comorb_other" )


format_percent <- function(x, digits = 1){
  paste0(round(x * 100, digits), "%")
}

for (var in cat_vars) {
  freq_table <- table(data_analysis[[var]], useNA = "always")
  prop_table <- prop.table(freq_table)
  
  report <- data.frame(
    Category = names(freq_table),
    Count = as.vector(freq_table),
    Percent = format_percent(as.vector(prop_table)),
    stringsAsFactors = FALSE
  )
  
  
  print(report, row.names = FALSE)
}
```


#### 处理极端值
```{r}

clean_limits <- list(
  age_years = c(16, 110),
  min_gcs_24h = c(3, 15),
  min_platelets_24h = c(1, 1000),
  max_creatinine_24h = c(0.1, 15),
  min_map_24h = c(20, 140),
  min_sysbp_24h = c(40, 260),
  max_hr_24h = c(20, 250),
  max_resp_24h = c(5, 80),
  min_spo2_24h = c(50, 100),
  min_temp_24h = c(30, 42),
  max_temp_24h = c(35, 43),
  max_glucose_24h = c(40, 600),
  max_bilirubin_24h = c(0, 40)
)


data_analy_clean <- data_analysis

for (v in names(clean_limits)) {
  lo <- clean_limits[[v]][1]
  hi <- clean_limits[[v]][2]
  data_analy_clean[[v]] <- ifelse(data_analy_clean[[v]] < lo | data_analy_clean[[v]] > hi, NA, data_analy_clean[[v]])
}

```

```{r}
colSums(is.na(data_analy_clean[names(clean_limits)]))

```

#### Check the correlation between continuous variables

```{r}
cor_mat <- cor(data_analy_clean[, con_vars], use = "pairwise.complete.obs", method = "spearman")

var_order <- colnames(cor_mat)              
cor_df <- as.data.frame(cor_mat)
cor_df$var1 <- rownames(cor_df)

cor_long <- cor_df |>
  pivot_longer(-var1, names_to = "var2", values_to = "corr") |>
  mutate(
    var1 = factor(var1, levels = rev(var_order)),  
    var2 = factor(var2, levels = var_order)
  )

ggplot(cor_long, aes(var2, var1, fill = corr)) +
  geom_tile(color = "white") +
  geom_text(aes(label = sprintf("%.2f", corr)), size = 3) +
  scale_fill_gradient2(low = "#E57373", mid = "white", high = "#4DB6AC", limits=c(-1,1)) +
  coord_fixed() +
  labs(x="", y="", title="Spearman Correlation (Cleaned Data)") +
  theme_bw() +
  theme(axis.text.x = element_text(angle=45, hjust=1))
```

### Relationship between in-hospital outcome and continuous variables

```{r}
vars_demo <- c("age_years")
vars_hemo <- c("min_map_24h","min_sysbp_24h","max_hr_24h")
vars_resp <- c("max_resp_24h","min_spo2_24h")
vars_temp <- c("min_temp_24h","max_temp_24h")
vars_lab  <- c("max_glucose_24h","max_creatinine_24h","min_platelets_24h","max_bilirubin_24h")
vars_neuro <- c("min_gcs_24h")

make_box <- function(df, vars, title){
  df |>
    select(death, all_of(vars)) |>
    pivot_longer(-death, names_to="variable", values_to="value") |>
    ggplot(aes(x=factor(death), y=value, fill=factor(death))) +
    geom_violin(trim=FALSE, alpha=0.3) +
    geom_boxplot(width=0.2, outlier.alpha = 0.2) +
    stat_compare_means(method="wilcox.test", label="p.signif") +
    facet_wrap(~variable, scales="free", ncol=3) +
    scale_fill_manual(values=c("#E57373","#4DB6AC")) +
    labs(title=title, x="Death", y="Value") +
    theme_bw(base_size=12) +
    theme(legend.position="none",
          strip.text = element_text(face="bold"))
}

make_box(data_analy_clean, vars_demo, "Demographics")
make_box(data_analy_clean, vars_hemo, "Hemodynamic Variables")
make_box(data_analy_clean, vars_resp, "Respiratory Variables")
make_box(data_analy_clean, vars_temp, "Temperature Variables")
make_box(data_analy_clean, vars_lab,  "Laboratory Results")
make_box(data_analy_clean, vars_neuro,"Neurologic Status")
```

#### ICU Type vs in-hospital outcome
```{r}
data_analy_clean |>
  group_by(icu_type) |>
  summarise(
    mortality = mean(ifelse(death == 1, 1, 0)) * 100,
    n = n()
  ) |>
  arrange(desc(mortality))
```
根据这个选择使用MICU 作为模型拟合时的基线 class，因为MICU 的样本量最大，粗死亡率是最高的

## Q1.1.3 Outliers and missing data handling
Exploratory data analysis and data cleaning were performed after determine the cohort and extract the covariates. Errors can appear in data collection and entry, sanity check and distribution check suggested that extreme outliers that exceed the reasonable physiological range existed. For all continuous indicators, reasonable ranges were defined and any data points exceeding the ranges were regarded as data entry errors and marked as missing values (NA).
Thorough missing data analysis were performed on the data and reported that extreme high missing rates over 85% in bedside measured vital signs including heart rate (max), SpO2 (min), respiratory rate (max), mean arterial pressure (min), body temperature (max & min), systolic blood pressure (min) and glucose (max). Bilirubin has a moderate missing rate over 50%, while platelets, GCS and creatinine had extremely low missing rate lower than 2%. The 2 observations with missing comorbidity information were deleted from the cohort, resulting in 32243 samples. Missing pattern check and visualization suggested that missing of vital signs presented high synchronization, with a missing correlation coefficient close to 1. The assumption that no measurement indicating rather stable condition was accepted. Normal value imputation was applied on bedside measurements and low missing rate variables. Missing of bilirubin has statistically significant association with the in-hospital outcome and ICU type, and Multiple Imputation by Chained Equations (MICE) (Azur, 2011) was applied to impute the variable. Given the joint missingness of vital signs, instead of creating separate missing markers for each variable, a new continuous variable was created to represent the number of missing indicators in vital signs covariates with high missing rates. A separate missing flag variable was created for bilirubin. 

Vital signs的缺失基本是共同发生的，因此不对每个变量进行单独的缺失标志的创建，而是创建一个新的连续变量，用于表示患者在关键生理指标上的缺失数量。

#### Check missing pattern

```{r}
vis_miss(data_analy_clean, warn_large_data = FALSE) 

```

```{r}
library(UpSetR)
vars_high <- c("min_temp_24h","max_temp_24h","max_glucose_24h",
               "max_resp_24h","min_sysbp_24h","min_map_24h",
               "max_hr_24h","min_spo2_24h","max_bilirubin_24h")

library(corrplot)

mat <- is.na(data_analy_clean[vars_high]) * 1
corr <- cor(mat)
corrplot(corr, method = "color", tl.col="black", tl.cex = 0.8)
```

```{r}
# Check the missing pattern
vars_test <- c("min_map_24h","min_spo2_24h","max_hr_24h","max_resp_24h","min_sysbp_24h","max_glucose_24h", "min_temp_24h", "max_temp_24h", "max_bilirubin_24h")

for(v in vars_test){
  data_analy_clean[[paste0("miss_",v)]] <- as.integer(is.na(data_analy_clean[[v]]))
  print(v)
  print(summary(glm(data_analy_clean[[paste0("miss_",v)]] ~ death + icu_type +age_years,
                    data=data_analy_clean, family=binomial)))
}

```
There is no obvious missing  pattern of vital signs, while the missing of `max_bilirubin_24h` is not random.

 Although the high missing ratio, the variables are important potential confounders that reflecting the severity of the disease, clinical decision-making, and the intensity of monitoring.

The vital signs variables will be imputed with normal values and `max_bilirubin_24h` will be imputed with MICE.

```{r}
data_analy_clean <- data_analy_clean |>
  filter(!if_any(starts_with("Comorb_"), is.na))
dim(data_analy_clean)
```

### 保守填补并创建缺失标识
由于缺失模式检查发现vital signs 
```{r}
vitals_missing_vars <- c("min_temp_24h", "max_temp_24h", "max_glucose_24h", "max_resp_24h", "min_sysbp_24h", "min_map_24h", "max_hr_24h", "min_spo2_24h")
```

```{r}
data_imputed_normal <- data_analy_clean |>
  mutate(
    vitals_missing_count = rowSums(across(all_of(vitals_missing_vars), ~ is.na(.x))),
    max_bilirubin_24h_missing_flag = as.integer(is.na(max_bilirubin_24h))
  ) |>
  mutate(
     min_temp_24h = replace_na(min_temp_24h, 37.0),
     max_temp_24h = replace_na(max_temp_24h, 37.0),
     max_glucose_24h = replace_na(max_glucose_24h, 120),
     max_resp_24h = replace_na(max_resp_24h, 18),
     min_sysbp_24h = replace_na(min_sysbp_24h, 100),
     min_gcs_24h = replace_na(min_gcs_24h, 15),
     max_creatinine_24h = replace_na(max_creatinine_24h, 1.0), 
     min_map_24h = replace_na(min_map_24h, 70), 
     max_hr_24h = replace_na(max_hr_24h, 90),
     min_spo2_24h = replace_na(min_spo2_24h, 98),
     min_platelets_24h = replace_na(min_platelets_24h, 200)
   ) |>
   mutate(
     across(ends_with("flag"), as.factor)
   )

```

```{r}
dim(data_imputed_normal)
```

```{r}
colSums(is.na(data_imputed_normal))
```
```{r}
data_imputed_normal$icu_type <- relevel(data_imputed_normal$icu_type, ref = "MICU")
```



```{r}
vars_mice_model <- c("max_bilirubin_24h", "death", "icu_type", "age_years", "gender", "ethnicity", "admission_type", "insurance", "comorb_cardio", "comorb_renal", "comorb_pulm", "comorb_diabetes", "comorb_cancer", "comorb_other","comorb_liver", "min_gcs_24h", "min_platelets_24h", "max_creatinine_24h", "min_map_24h", "max_hr_24h", "min_spo2_24h", "max_resp_24h","min_sysbp_24h", "min_temp_24h", "max_temp_24h", "max_glucose_24h",  "vitals_missing_count", "max_bilirubin_24h_missing_flag"  )

data_imp <- data_imputed_normal[, vars_mice_model]


initial <- mice(data_imp, maxit = 0)
meth <- initial$method
pred <- initial$predictorMatrix

meth[] <- ""

meth["max_bilirubin_24h"] <- "pmm"

pred[,] <- 0

pred["max_bilirubin_24h", c("death", "icu_type", "age_years")]
imp <- mice(data_imp, m = 5, mthod = meth, predictorMatrix = pred, seed = 42)
```
```{r}
comp1 <- complete(imp, 1)
data_imputed_mice <- data_imputed_normal
data_imputed_mice$max_bilirubin_24h_imp <- comp1$max_bilirubin_24h
```

```{r}
dim(comp1)
dim(data_imputed_mice)
```


```{r}
p_map <- data_imputed_normal %>%
  ggplot(aes(x = min_map_24h)) +
  geom_histogram(bins = 50, fill = "#4DB6AC", color = "black") +
  geom_vline(xintercept = 70, color = "#E57373", linetype = "dashed", linewidth = 1) +
  labs(title = "min_map_24h distribution after inputation (red)", x = "MAP (mmHg)", y = "Frequency") +
  theme_minimal()

print(p_map)  
```
### Q1.1.4 Statistical analysis and model selection
Multivariable logistic regression model were built to estimate ICU type total effect on binary in-hospital outcome. According to EDA results that MICU presented the largest sample size of 10,937 and the highest crude mortality rate, MICU is defined as the reference category in the logistic models.

插入模型公式

Given the use of MICE, the model with MICE imputed variables will be fitted on MICE completed data separately and the coefficients, standard errors and confidence intervals of the final model will be merged using Rubin's Rules.

Progressive multivariate regression method was applied to fit 3 nested models(Table). The main model of this question is Model 2 which included all confounding factors.

插入表格



### Q1.1.5 Model diagnostics
Use variance inflaction factor (VIF) to evaluate multicollinearity between independent variables. VIF > 5 would be regarded as severe collinearity, and the variables would be combined with other variables or excluded. 
Cook's Distance (Cook, 1977) was calculated to examine if there were any single points that had excessive and systematic impact on the estimated coefficients, and 0.01 was defined as the threshold. 
Hosmer-Lemeshow test (Hosmer, 1980) was used to evaluate the goodness-of-fit, and P-value>0.05 was acceptable, indicating that the model fitting of the data is sufficient and acceptable. Studies reported that the hypothesis of perfect fit is more likely to be rejected when testing with large sample size (Nattino, 2018; Liu, 2020). Given the large cohort in the study, 5000 observations were sampled to perform the test. 
Although the model is not used to predict, the discriminative ability was also evaluated by ROC and AUC. The higher AUC value indicates the better ability to distinguish different outcomes.
VIF, Hosmer-Lemeshow test and AUC were evaluated on all 5 imputed data set, Cook's Distance was calculated on one representative imputed data set.
Another two models were fitted to perform sensitivity analysis to test the robustness of the main model. Model 3 excluded covariates with missing rate higher than 50% and was fitted with the complete cases. Model 4 included all covariates and was fitted with complete samples.

插入Model3 和 Model4

## Q1.2 Results
### Q1.2.1 Descriptive statistics of cohort
Totally 32,243 ICU stay encounters are included in the analysis, among which MICU had most ICU stays (n = 10.937, 34.0%). The overall age mean of the patients was 63.2 (17.5), and CCU patients had the highest age mean of 67.9. Most of the patients (80.0%) were admitted to the hospital through emergency. There were significant differences in the burden of comorbidities among patients of various ICU types. Most  patients payed though  Medicare (52.3%) or private (35.1%) insurance. Cardiovascular comorbidity is the most common in CCU (74.3%), while the proportion pulmonary comorbidity reached 67.1%. White people are the majority population. As for the in-hospital outcomes, the overall in-hospital mortality was 4.5% and there were statistically significant differences (P < 0.001) between the mortality rates of various ICU types. MICU had the highest mortality rate of 6.8%, while CSICU had the lowest mortality rate of 1.4%.


```{r}
# Use`data_imputed_normal`, n = 32243
str(data_imputed_normal)
```
```{r}

demo_vars <- c("age_years", "gender", "icu_type", "admission_type", "insurance", "ethnicity", "comorb_cardio", "comorb_renal", "comorb_pulm", "comorb_diabetes", "comorb_cancer", "comorb_liver", "comorb_other", "death")

data_imputed_normal |>
  select(all_of(demo_vars)) |>
  mutate(
    across(starts_with("comorb_"), ~factor(.x, levels = c("0","1"), labels = c("No","Yes"))),
    death = factor(death, levels = c(0, 1,"0", "1"), labels = c("Alive","Died","Alive","Died"))
  ) |>
  tbl_summary(
    by = "icu_type",
    statistic = list(
      all_continuous() ~ "{mean} ({sd})",
      all_categorical() ~ "{n} ({p}%)"
    ),
    digits = list(
      all_continuous() ~ 1, 
      all_categorical() ~ 1
    ),
    missing = "ifany",
    label = list(
      age_years ~ "Age (years)",
      gender ~ "Gender",
      admission_type ~ "Admission Type", 
      insurance ~ "Insurance",
      ethnicity ~ "Ethnicity",
      comorb_cardio ~ "Cardiovascular Comorbidity", 
      comorb_renal ~ "Renal Comorbidity",
      comorb_pulm ~ "Pulmonary Comorbidity", 
      comorb_diabetes ~ "Diabetes", 
      comorb_cancer ~ "Cancer", 
      comorb_liver ~ "Liver Disease", 
      comorb_other ~ "Other Comorbidity",
      death ~ "In-hospital Outcome"
    )
  ) |>
  add_overall(last = TRUE) |>
  add_p() |>
  modify_header(label = "**Variable**") |>
  bold_labels()
```




(1) Model0: Modelling with only `icu_type` included as independent variable on the imputed data
(2) Model1: Model0 + Demographics
(3) Model2: Model1 + Comorbidity + severity of disease( Vital signs & Lab measurements) + Missing flags
(3) sensitivity model removing variables with >50% missingness and performing complete-case analysis,
(4) complete-case full-variable model including all predictors without imputation.
```{r}
data_imputed_mice$icu_type <- relevel(data_imputed_mice$icu_type, ref = "MICU")
```

#### Model 0 modelling with only ICU type on imputed data
```{r}
mod0 <- glm(death ~ icu_type, data = data_imputed_mice, family = binomial)

summary(mod0)
```

```{r}
exp(cbind(OR = coef(mod0), confint(mod0)))
```

#### Model 1: mod0 + demographics on imputed data
```{r}
mod1 <- glm(death ~ icu_type + age_years + gender + ethnicity + admission_type + insurance, data = data_imputed_mice, family = binomial)

summary(mod1)

```

```{r}
exp(cbind(OR = coef(mod1), confint(mod1)))
```

#### Model 2 mod1 + comorbidity + severity of disease on imputed data
```{r}
  
demographic_comorbidity <- "age_years + gender + ethnicity + admission_type + insurance + comorb_cardio + comorb_renal + comorb_pulm + comorb_diabetes + comorb_cancer + comorb_other + comorb_liver"

imputed_vars <- "min_gcs_24h + min_platelets_24h + max_creatinine_24h + min_map_24h + max_hr_24h + min_spo2_24h + max_resp_24h + min_sysbp_24h + min_temp_24h + max_temp_24h + max_glucose_24h + max_bilirubin_24h"

missing_flags <- "vitals_missing_count + max_bilirubin_24h_missing_flag"

formula <- paste("death ~ icu_type +", demographic_comorbidity, "+", imputed_vars, "+", missing_flags )

cat(formula, "\n")

mod2 <- with(imp, {
  icu_type <- relevel(icu_type, ref = "MICU")
  
  glm(as.formula(formula), family = binomial)
  })
pool2 <- pool(mod2)

summary(pool2)
```

```{r}
s <- summary(pool2)
tval <- qt(0.975, df = s$df)
lower <- s$estimate - tval * s$std.error
upper <- s$estimate + tval * s$std.error

or_tab <- data.frame(
  term = s$term,
  OR = exp(s$estimate),
  LCL95 = exp(lower),
  UCL95 = exp(upper),
  p.value = s$p.value
)

or_tab
```




```{r}
# Model 0
mod0_coef <- coef(summary(mod0))
mod0_tab <- data.frame(
  term = rownames(mod0_coef),
  estimate = mod0_coef[, "Estimate"],
  std.error = mod0_coef[, "Std. Error"],
  p.value = mod0_coef[, "Pr(>|z|)"]
) |>
  filter(grepl("^icu_type", term)) |>
  mutate(
    OR = exp(estimate),
    conf.low = exp(estimate - 1.96 * std.error),
    conf.high = exp(estimate + 1.96 * std.error),
    model = "Model 0" 
) |>
  select(model, term, OR, conf.low, conf.high, p.value )

# Model 1
mod1_coef <- coef(summary(mod1))
mod1_tab <- data.frame(
  term = rownames(mod1_coef),
  estimate = mod1_coef[, "Estimate"],
  std.error = mod1_coef[, "Std. Error"],
  p.value = mod1_coef[, "Pr(>|z|)"]
) |>
  filter(grepl("^icu_type", term)) |>
  mutate(
    OR = exp(estimate),
    conf.low = exp(estimate - 1.96 * std.error),
    conf.high = exp(estimate + 1.96 * std.error),
    model = "Model 1" 
) |>
  select(model, term, OR, conf.low, conf.high, p.value )

# Model 2
s <- summary(pool2)
tval <- qt(0.975, df = s$df)
lower <- s$estimate - tval * s$std.error
upper <- s$estimate + tval * s$std.error
mod2_tab <- data.frame(
  term = s$term,
  OR = exp(s$estimate),
  conf.low = exp(lower),
  conf.high = exp(upper),
  p.value = s$p.value
) |>
  filter(grepl("^icu_type", term)) |>
  mutate(model = "Model 2")


```


```{r}
# Output table
estimate_summary <- bind_rows(mod0_tab, mod1_tab, mod2_tab) |>
  mutate(
    term = as.character(term),
    term = case_when(
      term == "icu_typeCCU"   ~ "CCU vs MICU",
      term == "icu_typeCSRU"  ~ "CSRU vs MICU",
      term == "icu_typeSICU"  ~ "SICU vs MICU",
      term == "icu_typeTSICU" ~ "TSICU vs MICU",
      TRUE ~ term
    ),
    OR = round(OR, 2),
    conf.low = round(conf.low, 2),
    conf.high = round(conf.high, 2),
    CI95 = paste0("(", conf.low, ", ", conf.high, ")"),
    p.value = ifelse(p.value < 0.001, "<0.001", round(p.value, 3))
  ) |>
  select(ICU_Type = term, Model = model, OR, CI95, p.value) 

rownames(estimate_summary) <- NULL 

estimate_summary |>
  arrange(ICU_Type, Model) |>
  kbl(
    caption = "Odds Ratios and p-values for ICU types across models",
    align = "lccccc",
    digits = 3
  ) |>
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed"),
    full_width = FALSE,
    position = "center",
    font_size = 13
  ) |>
  column_spec(1, bold = TRUE, width = "4cm") %>%
  column_spec(2, italic = TRUE, width = "4cm") %>%
  column_spec(3:4, width = "2.5cm")

```
### Q1.2.3 Model estimates
The three logistic regression models were fitted to estimate the association between ICU type and in-hospital outcome.
The estimates of the unadjusted model (Model 0) reported that CCU (OR = 0.62, CI[0.53, 0.73]), CSRU (OR = 0.19, CI[0.15, 0.24]), SICU (OR = 0.66, CI[0.57, 0.76]), and TSICU (OR = 0.49, CI[0.41, 0.58]), indicating significantly lower risk of in-hospital death (all p < 0.001) compared with MICU.
The partial-adjusted model (Model 1) adjusted for demographic factors. Slight changes appeared in OR and reported that CCU had OR = 0.50 (CI[0.43, 0.59]), CSRU had OR = 0.22 (CI[0.18, 0.28]), SICU  had OR = 0.75 (CI[0.64, 0.87]), and TSICU had OR = 0.60 (CI[0.50, 0.72]).
The fully adjusted model (Model 2) adjusted for comorbidity and severity of disease. OR in all ICU types were still less than 1 and the associations between ICU type and in-hospital outcome were still statistically significant. CSRU still reported the lowest OR of 0.20 (CI[0.15, 0.25]) and the OR value of TSICU changed most significantly, rising sharply from 0.49 in Model 0 to 0.77 (CI[0.64, 0.94]). CCU (OR = 0.66, CI[0.56, 0.79]) and SICU (OR = 0.74, CI[0.63, 0.87]) also reported with higher OR than in Model 0.

### Q1.2.4 Model diagnostics
Model diagnositics were performed on the fully adjusted model. Multicollinearity test repoted that All adjusted GVIF values of covariates were lower than 2.5, indicating no serious multicollinearity concern. The goodness-of-fit was tested through Hosmer-Lemeshow test. The tests across all 5 imputed datasets reported p-values from 0.1804 to 0.4004, with the mean p-value of 0.2628. The results suggested no evidence of lack of fit. AUC were calculated on all 5 imputed datasets and reported mean AUC of 0.818. 
Approximately 230 influential data points were identified in Cook's Distance test with threshold of 0.001, and the maximum value of Cook's distance is around 0.004. The model were refitted after removing the influential data points and the refitted model demonstrated slight differences Model 2 in OR and 95% CI.
### Q1.2.5 Sensitivity analysis
Another two models were fitted to test the reliability of the fully adjusted model.As shown in the table, the estimates of Model 3 were highly consistent with the fully adjusted model(Model 2). The OR of CCU was 0.63, that of CSRU was 0.17, that of SICU was 0.71, and that of TSICU was 0.70. All the results were statistically significant. The estimates of Model 4 presented significant differences from Model 2. The OR of CCU was 0.56, that of CSRU was 0.30, that of SICU was 0.51, and that of TSICU was 0.90. The ORs of CCU and TSICU had no statistical significance (p > 0.05). The 95% confidence intervals became wide.

#### Model diagnostics on main model

```{r}
# VIF of main model "mod2"
comp1$icu_type <- relevel(comp1$icu_type, ref = "MICU")

mod_vif <- glm(as.formula(formula), data = comp1, family = binomial)

vif_mod2 <- vif(mod_vif)
print(vif_mod2)
```


Hosmer-Lemeshow on main model "mod2"
```{r}
M <- imp$m                 
hl_pvalues <- numeric(M)   
sample_size <- 5000     


for (i in 1:M) {
  
  # Extract the data set
  data_i <- complete(imp, i)
  
  # Sampelling
  n_i <- nrow(data_i)
  if (n_i > sample_size) {
    set.seed(123 + i)  
    idx <- sample(n_i, sample_size)
    data_i_sub <- data_i[idx, ]
  } else {
    data_i_sub <- data_i
  }
  
  
  mod_i <- tryCatch(
    glm(as.formula(formula), data = data_i_sub, family = binomial),
    error = function(e) {
      cat(sprintf("The %d imputed dataset failed in fitting: %s\n", i, e$message))
      return(NULL)
    }
  )
  
  if (!is.null(mod_i)) {
    hl_i <- tryCatch(
      hoslem.test(mod_i$y, fitted(mod_i), g = 10),
      error = function(e) {
        cat(sprintf("The %d imputed failed in  H-L test: %s\n", i, e$message))
        return(NULL)
      }
    )
    
    if (!is.null(hl_i)) {
      hl_pvalues[i] <- hl_i$p.value
    } else {
      hl_pvalues[i] <- NA
    }
  } else {
    hl_pvalues[i] <- NA
  }
}

cat("---- Examine each result ----\n")
print(hl_pvalues)


valid_pvalues <- hl_pvalues[!is.na(hl_pvalues)]

cat("---- Suumary ----\n")
if (length(valid_pvalues) > 0) {
  cat(sprintf("Min p = %.4f, Max p = %.4f, Mean p = %.4f\n",
              min(valid_pvalues), max(valid_pvalues), mean(valid_pvalues)))
  cat(sprintf("Proportion of  p < 0.05 : %.2f\n", mean(valid_pvalues < 0.05)))
} else {
  cat("All test failed.\n")
}
```

AUC
```{r}
auc_values <- numeric(M)

for(i in 1:M){
  dat_i <- complete(imp,i)
  
  fit_i <- glm(as.formula(formula), data = dat_i, family=binomial)
  
  pred_i <- predict(fit_i, type = "response")
  
  roc_i <- roc(response = dat_i$death, predictor = pred_i, quiet = TRUE)
  auc_values[i] <- as.numeric(auc(roc_i))
}

print(auc_values)

valid_auc <- auc_values[!is.na(auc_values)]
cat(sprintf("Min AUC = %.3f, Max AUC = %.3f, Mean AUC = %.3f\n",
            min(valid_auc), max(valid_auc), mean(valid_auc)))

```
```{r}
fit1 <- glm(as.formula(formula), data = comp1, family = binomial)
pred1 <- predict(fit1, type = "response")
roc1 <- roc(dat1$death, pred1)

plot(roc1, col = "#4DB6AC", lwd = 2, main = "ROC Curve for Model 2 (Imputed Dataset 1)")
auc(roc1) 
```


```{r}
# Function examine cook's distance
check_cooksd <- function(model_formula, data, cutoff = 0.001) {
  mod <- glm(as.formula(model_formula), data = data, family = binomial)
  cooksd <- cooks.distance(mod)

  
  influential_points <- which(cooksd > cutoff)
  
  cat(sprintf("In dataset with n=%d samples，use the fixed threshold cutoff= %.5f\n",  nrow(data), cutoff))
  cat(sprintf("%d point \n", length(influential_points)))
  
  
  return(data.frame(ID = names(influential_points), Cooksd = cooksd[influential_points]))
}


all_influential <- list()
for (i in 1:M) {
  data_i <- complete(imp, i)
  all_influential[[i]] <- check_cooksd(formula, data_i, cutoff = 0.001)
}

```

```{r}
fit1 <- glm(as.formula(formula), data = comp1, family = binomial)
cookd <- cooks.distance(fit1)

cutoff <- 0.001

plot(1:length(cookd),
     cookd, type = "h",
     main = "Cook's Diatance (Imputed Dataset 1)",
     xlab = "Observation Index",
     ylab = "Cook's distance")
abline(h = cutoff, col = "#E57373", lty =2)

points(which(cookd > cutoff), cookd[cookd > cutoff],
       col ="#E57373", pch = 19)

```


```{r}
idx_high <- which(cookd > cutoff)

dat1 <- complete(imp, 1)

fit_full <- glm(as.formula(formula), data = dat1, family = binomial)
fit_drop <- glm(as.formula(formula), data = dat1[-idx_high, ], family = binomial)

library(broom)
or_full <- tidy(fit_full, exponentiate = TRUE, conf.int = TRUE)  |> 
  filter(grepl("^icu_type", term)) |> 
  mutate(model = "full")

or_drop <- tidy(fit_drop, exponentiate = TRUE, conf.int = TRUE)  |> 
  filter(grepl("^icu_type", term)) |> 
  mutate(model = "drop_high_cooks")


```

```{r}

compare_or <- rbind(or_full, or_drop) |>
  mutate(
    term = case_when(
      term == "icu_typeCCU"   ~ "CCU vs MICU",
      term == "icu_typeCSRU"  ~ "CSRU vs MICU",
      term == "icu_typeSICU"  ~ "SICU vs MICU",
      term == "icu_typeTSICU" ~ "TSICU vs MICU",
      TRUE ~ term),
    model = ifelse(model == "full", "Full model", "High Cook’s D removed"),
    OR = round(estimate, 2),
    CI95 = paste0("(", round(conf.low, 2), ", ", round(conf.high, 2), ")"),
    p.value = ifelse(p.value < 0.001, "<0.001", round(p.value, 3))
  ) |>
  select(ICU_Type = term, Model = model,  OR, CI95, p.value)

rownames(compare_or) <- NULL
compare_or |>
  arrange(ICU_Type, Model)|>
  kbl(
    caption = "Sensitivity Analysis: ICU Type Effects before and after removing high Cook’s D cases",
    align = "lcccc",
    digits = 3
  ) |>
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed"),
    full_width = FALSE,
    position = "center",
    font_size = 13
  ) |>
  column_spec(1, bold = TRUE, width = "4cm") |>
  column_spec(2, italic = TRUE, width = "4cm") |>
  column_spec(3:4, width = "2.5cm")
  

```

#### Sensitivity analysis model
#### Model 3： Modelling with data removed variabels with missing values over 50% and keep the complete samples
```{r}
data_low_missing <- data_analy_clean |> 
  select(-min_temp_24h, -max_temp_24h, -max_glucose_24h, -max_resp_24h, -min_sysbp_24h, -min_map_24h, -max_hr_24h, -min_spo2_24h, -max_bilirubin_24h) |>
  drop_na()

data_low_missing$icu_type <- relevel(data_low_missing$icu_type, ref = "MICU")

demographic_comorbidity <- "age_years + gender + ethnicity + admission_type + insurance + comorb_cardio + comorb_renal + comorb_pulm + comorb_diabetes + comorb_cancer + comorb_other+comorb_liver"

other_confounders <- "min_gcs_24h + min_platelets_24h + max_creatinine_24h"

formula3 <- paste("death ~ icu_type +", demographic_comorbidity, "+", other_confounders)

mod3 <- glm(as.formula(formula3), data = data_low_missing, family = binomial())

summary(mod3)

```
```{r}
exp(cbind(OR = coef(mod3), confint(mod3)))
```

#### Model 4: Modelling with samples with complete values (Keep all confounding variables)
```{r}
data_complete <- na.omit(data_analy_clean)

data_complete$icu_type <- relevel(data_complete$icu_type, ref = "MICU")

formula4 <- death ~ icu_type + age_years + gender + ethnicity + admission_type + insurance + comorb_cardio + comorb_renal + comorb_pulm + comorb_diabetes + comorb_cancer + comorb_other+comorb_liver + min_gcs_24h + min_platelets_24h + max_creatinine_24h + min_map_24h + max_hr_24h + min_spo2_24h + max_resp_24h + min_sysbp_24h + min_temp_24h + max_temp_24h + max_glucose_24h + max_bilirubin_24h   

mod4 <- glm(as.formula(formula4), data = data_complete, family = binomial())

summary(mod4)
```

```{r}
exp(cbind(OR = coef(mod4), confint(mod4)))
```
```{r}
# Model 3
mod3_coef <- coef(summary(mod3))
mod3_tab <- data.frame(
  term = rownames(mod3_coef),
  estimate = mod3_coef[, "Estimate"],
  std.error = mod3_coef[, "Std. Error"],
  p.value = mod3_coef[, "Pr(>|z|)"]
) |>
  filter(grepl("^icu_type", term)) |>
  mutate(
    OR = exp(estimate),
    conf.low = exp(estimate - 1.96 * std.error),
    conf.high = exp(estimate + 1.96 * std.error),
    model = "Model 3" 
) |>
  select(model, term, OR, conf.low, conf.high, p.value )

# Model 4
mod4_coef <- coef(summary(mod4))
mod4_tab <- data.frame(
  term = rownames(mod4_coef),
  estimate = mod4_coef[, "Estimate"],
  std.error = mod4_coef[, "Std. Error"],
  p.value = mod4_coef[, "Pr(>|z|)"]
) |>
  filter(grepl("^icu_type", term)) |>
  mutate(
    OR = exp(estimate),
    conf.low = exp(estimate - 1.96 * std.error),
    conf.high = exp(estimate + 1.96 * std.error),
    model = "Model 4" 
) |>
  select(model, term, OR, conf.low, conf.high, p.value )


```

```{r}
# Output table
sensitivity_summary <- bind_rows(mod3_tab, mod4_tab) |>
  mutate(
    term = as.character(term),
    term = case_when(
      term == "icu_typeCCU"   ~ "CCU vs MICU",
      term == "icu_typeCSRU"  ~ "CSRU vs MICU",
      term == "icu_typeSICU"  ~ "SICU vs MICU",
      term == "icu_typeTSICU" ~ "TSICU vs MICU",
      TRUE ~ term
    ),
    OR = round(OR, 2),
    conf.low = round(conf.low, 2),
    conf.high = round(conf.high, 2),
    CI95 = paste0("(", conf.low, ", ", conf.high, ")"),
    p.value = ifelse(p.value < 0.001, "<0.001", round(p.value, 3))
  ) |>
  select(ICU_Type = term, Model = model, OR, CI95, p.value) 

rownames(sensitivity_summary) <- NULL 

sensitivity_summary |>
  arrange(ICU_Type, Model) |>
  kbl(
    caption = "Odds Ratios and p-values for ICU types across sensitivity analysis models",
    align = "lccccc",
    digits = 3
  ) |>
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed"),
    full_width = FALSE,
    position = "center",
    font_size = 13
  ) |>
  column_spec(1, bold = TRUE, width = "4cm") |>
  column_spec(2, italic = TRUE, width = "4cm") |>
  column_spec(3:4, width = "2.5cm")
```

## Q1.3 Discussion


 indicating that the estimates of the model were not driven by the influential data points and the model estimates were robust and reliable.



# Question 2
## Q2.1 Methods
### Q2.1.2 Data source and cohort
The same data MIMIC-III v1.4 was used in Question 2.

MIMIC-III v1.4 contains 53423 distinct hospital admissions, and during each admission a patient could have stayed in ICU more than once. The project started with 61532 total ICU stay encounters after removing a duplicated ICU stay encounter (unique ICU stay ID = 229922).

In this question, the analysis was based on unique ICU stay encounters rather than unique patient identifiers, which resulted in a total of 38509 unique ICU stay. The admissions without clear hospital outcome are also remove, resulting in 32,245 unique ICU stay.

```{r}
data_filter2 <- pt_icu_outcome |>  
  
# Filter records of patients age >= 18
  filter(age_years >= 18) 
dim(data_filter2)  

# Filter ICU stays with los less than 24h
data_filter <- data_filter |>  
  filter(los >= 1) 
dim(data_filter2)

# Ensure los in ICU exist
data_filter2 <- data_filter2 |>   

  filter(!is.na(los))

dim(data_filter2)

# Link the data tables
data_merge2 <- data_filter2 |>
  
  left_join(
    icustays |> select(icustay_id, first_careunit),
    by = "icustay_id"
  ) |>
  mutate(
    icu_type = as.factor(first_careunit)
  ) |>
  
  left_join(
    patients |> select(subject_id, gender),
    by = "subject_id"
  ) |>
  
  left_join(
    admissions |> select(hadm_id, admission_type, insurance, ethnicity),
    by = "hadm_id"
  ) |>
  
  left_join(
    comorbidity_groups, by = "hadm_id"
  ) |>
  
  mutate(
    # Binary indicator of length of stay
    prolonged_los = factor(ifelse(los >= 7, 1,0),
                           levels = c(0,1),
                           labels = c("short stay", "prolonged stay")),
    gender = as.factor(gender),               
    insurance = as.factor(insurance),         
    ethnicity = as.factor(ethnicity),         
    admission_type = as.factor(admission_type),
    first_careunit = as.factor(first_careunit),
    
    # Recode the ethnicity
    ethnicity = case_when(
      str_detect(ethnicity, "WHITE") ~ "WHITE",
      str_detect(ethnicity, "BLACK|AFRICAN AMERICAN") ~ "BLACK",
      str_detect(ethnicity, "HISPANIC|LATINO") ~ "HISPANIC",
      TRUE ~ "OTHER/UNKNOWN"
    ),
    ethnicity = as.factor(ethnicity)
  ) |>
```


```{r}
hr_lower <- 20
hr_upper <- 250
resp_lower <- 5
resp_upper <- 80
sysbp_lower <- 40
sysbp_upper <- 260
map_upper <- 30
map_lower <- 160
spo2_lower <- 50
spo2_upper <- 100
temp_lower <- 30
temp_upper <- 43
glucose_lower <- 40
glucose_upper <- 600

```

```{r}
vitals_24hr_clean <- vitals_hourly |>
  filter(hr >= 0 & hr <= 24) |>
 
  mutate(
    map_clean = case_when(
      meanarterialpressure < map_lower ~ map_lower,
      meanarterialpressure > map_upper ~ map_upper,
      TRUE ~ meanarterialpressure
    ),
    resp_clean = case_when(
      resprate < resp_lower ~ resp_lower,
      resprate > resp_upper ~ resp_upper,
      TRUE ~ resprate
    ),
    sysbp_clean = case_when(
      sysbp < sysbp_lower ~ sysbp_lower,
      sysbp > sysbp_upper ~ sysbp_upper,
      TRUE ~ sysbp
    ),
    hr_clean = case_when(
      heartrate < hr_lower ~ hr_lower,
      heartrate > hr_upper ~ hr_upper,
      TRUE ~ heartrate
    ),
    spo2_clean = case_when(
      spo2 < spo2_lower ~ spo2_lower,
      spo2 > spo2_upper ~ spo2_upper,
      TRUE ~ spo2
    ),
    temp_clean = case_when(
      temperature < temp_lower ~ temp_lower,
      temperature > temp_upper ~ temp_upper,
      TRUE ~ temperature
    ),
    glucose_clean = case_when(
      glucose < glucose_lower ~ glucose_lower,
      glucose > glucose_upper ~ glucose_upper,
      TRUE ~ glucose 
    )
  ) |>
  select(icustay_id, map_clean, hr_clean, resp_clean, sysbp_clean, spo2_clean, temp_clean, glucose_clean) 
```


```{r}

colSums(is.na(vitals_24hr_clean))
```

```{r}
# Convert to long form
vitals_long <- vitals_24hr_clean |>
  pivot_longer(
    cols = c(hr_clean, map_clean, sysbp_clean,temp_clean, glucose_clean, spo2_clean, resp_clean),
    names_to = "variable",
    values_to = "value"
  )

# Feature engineering
quantile_features <- vitals_long |>
  group_by(icustay_id, variable) |>
  mutate(
    mean_val = mean(value, na.rm = TRUE),
    sd_val = sd(value, na.rm = TRUE)
  ) |>
  mutate(z = (value - mean_val)/sd_val) |>
  
  mutate(
    q_low = quantile(z, 0.25, na.rm = TRUE),
    q_high = quantile(z, 0.75, na.rm = TRUE)
  ) |>
  
  mutate(keep = z <= q_low | z >= q_high) |>
  
  summarise(
    n = n(),
    origin_mean = mean(value, na.rm = TRUE),
    origin_sd = ifelse(sum(!is.na(value)) > 1, sd(value, na.rm = TRUE),
                         ifelse(sum(!is.na(value)) == 1, 0, NA_real_)),
    mod_mean = ifelse(sum(keep, na.rm = TRUE) > 0,
                      mean(value[keep], na.rm = TRUE),
                      NA_real_),
    mod_sd   = ifelse(sum(keep, na.rm = TRUE) > 1,
                      sd(value[keep], na.rm = TRUE),
                      ifelse(sum(keep, na.rm = TRUE) == 1, 0, NA_real_)),
    quant_pct = ifelse(n > 0, sum(keep, na.rm = TRUE)/n, NA_real_),
    .groups = "drop"
  ) |>
  
  pivot_wider(
    names_from = variable, 
    values_from = c(origin_mean, origin_sd, mod_mean, mod_sd, quant_pct),
    names_glue = "{variable}_{.value}"
  ) |>
  
  mutate(across(
    where(is.numeric),
    function(x) ifelse(is.na(x), 1, 0),
    .names = "{.col}_missing"
  )) |>
  select(-icustay_id_missing, -n_missing)

```

```{r}
colSums(is.na(quantile_features))
```
```{r}
quantile_features_imputed <- quantile_features |>
  mutate(
    across(contains("map_clean_") & ends_with("_mean"), ~replace_na(.x, 85)),
    across(contains("hr_clean_") & ends_with("_mean"), ~replace_na(.x, 90)),
    across(contains("resp_clean_") & ends_with("_mean"), ~replace_na(.x, 18)),
    across(contains("sysbp_clean_") & ends_with("_mean"), ~replace_na(.x, 120)),
    across(contains("spo2_clean_") & ends_with("_mean"), ~replace_na(.x, 98)),
    across(contains("temp_clean_") & ends_with("_mean"), ~replace_na(.x, 37)),
    across(contains("glucose_clean_") & ends_with("_mean"), ~replace_na(.x, 120))
  ) 
  
```
为避免数据泄露，sd的插补只用训练集上的中位数进行插补

```{r}

  
  inner_join(
    quantile_features_imputed,
    by = "icustay_id"
  ) |> 
  drop_na(comorb_cardio, comorb_pulm, comorb_cancer, comorb_other,
          comorb_renal, comorb_diabetes, comorb_liver) |>
  
  select(-row_id, -dob, -admittime, -dischtime, -intime, -outtime, -hosp_deathtime, -icu_expire_flag, -hospital_expire_flag, -dod, -expire_flag, -ttd_days, -n, -los )
```

```{r}

data_ml_ready <- data_merge2 |>
  mutate(
    prolonged_los = ifelse(prolonged_los == "prolonged stay", 1, 0)
  ) |>
  fastDummies::dummy_cols(remove_first_dummy = TRUE, remove_selected_columns = TRUE)
str(data_ml_ready)
```

```{r}
set.seed(42)
ids <- unique(data_ml_ready$subject_id)       
train_ids <- sample(ids, size = floor(0.8 * length(ids)))
train_idx <- data_ml_ready$subject_id %in% train_ids

train_df <- data_ml_ready[train_idx, ]
test_df  <- data_ml_ready[!train_idx, ]
```

```{r}
sd_cols_train <- names(train_df)[grepl("_sd$", names(train_df))]
num_na_cols_train <- names(train_df)[sapply(train_df, function(x) is.numeric(x) && any(is.na(x)))]
cols_for_median <- union(sd_cols_train, num_na_cols_train)
median_par <- sapply(train_df[cols_for_median], function(x) median(x, na.rm = TRUE))
```


```{r}
impute_with_median_par <- function(df, par_named_vec){
  df|>
    mutate(across(all_of(names(par_named_vec)),
                  ~ ifelse(is.na(.x), par_named_vec[[cur_column()]], .x)))
}

train_imp <- impute_with_median_par(train_df, median_par)
test_imp <- impute_with_median_par(test_df, median_par)
```

```{r}
table(train_imp$prolonged_los)
table(test_imp$prolonged_los)
```
```{r}
# Create DMatrix
dtrain <- xgb.DMatrix(as.matrix(select(train_imp, -prolonged_los)), label = train_imp$prolonged_los)
dtest <- xgb.DMatrix(as.matrix(select(test_imp, -prolonged_los)), label = test_imp$prolonged_los)
```


Baseline model
```{r}
basic_params <- list(
    objective = "binary:logistic",
    eval_metric = "auc",
    max_depth = 6,
    eta = 0.1,
    subsample = 0.8,
    colsample_bytree = 0.8,
    min_child_weight = 1
)
```


```{r}
xgb_basic <- xgb.train(
  params = basic_params,
  data = dtrain,
  nrounds = 200,
  watchlist = list(train = dtrain, test = dtest),
  early_stopping_rounds = 20,
  print_every_n = 20
)
```

```{r}
# Simple evaluation of the baseline model
pred_basic <- predict(xgb_basic, dtest)
roc_basic <- roc(test_imp$prolonged_los, pred_basic)
auc_basic <- auc(roc_basic)
cat("Baseline Test AUC:", auc_basic, "\n")
```

```{r}
plot(roc_basic, col = "#4DB6AC", main = "ROC Curve - Baseline Model")
```

Fine-tuning  

```{r}
# Define hyper-parameters
param_grid <- expand.grid(
  max_depth = c(4L,5L,6L),
  eta = c(0.05, 0.1),
  subsample = c( 0.8),
  colsample_bytree = c(0.8),
  min_child_weight = c(1,2),
  gamma = c(0,0.5),
  KEEP.OUT.ATTRS = FALSE
)
```

```{r}
positive <- sum(train_imp$prolonged_los == 1)
negative <- sum(train_imp$prolonged_los == 0)
scale_pos_weight <- negative/positive
scale_pos_weight
```

Circular cross-validation
```{r}
best_auc <- 0
best_params <- list()

for (i in 1:nrow(param_grid)){
  params <- list(
    objective = "binary:logistic",
    eval_metric = c("auc", "logloss"),
    max_depth = param_grid$max_depth[i],
    eta = param_grid$eta[i],
    subsample = param_grid$subsample[i],
    colsample_bytree = param_grid$colsample_bytree[i],
    min_child_weight = param_grid$min_child_weight[i],
    scale_pos_weight = scale_pos_weight,
    gamma = param_grid$gamma[i]
    
  )
  
  cat("\nRunning CV", i, "of", nrow(param_grid), "\n")
  
  cv_result <- xgb.cv(
    params = params,
    data = dtrain,
    nrounds = 300,
    nfold = 5,
    metrics = c("auc", "logloss"),
    early_stopping_rounds = 20,
    verbose = FALSE
  )
  
  best_iter <- cv_result$best_iteration
  mean_auc <- max(cv_result$evaluation_log$test_auc_mean)
  
  if (mean_auc > best_auc){
    best_auc <- mean_auc
    best_params <- params
    best_nrounds <- best_iter
    }
}

cat("\nBest AUC:", best_auc, "\n")
print(best_params)
cat("Best nround:", best_nrounds,"\n")
```

Use the best parameters to train the model
```{r}
xgb_best <- xgb.train(
  params = best_params,
  data = dtrain,
  nrounds = best_nrounds,
  watchlist = list(train = dtrain, test = dtest),
  early_stopping_rounds = 20,
  print_every_n = 20
)
```

The model does not improved much than the baseline model.
Evaluate the current fine-tuned model first.

```{r}
pred_prob <- predict(xgb_best, dtest)
pred_class <- ifelse(pred_prob >= 0.5, 1, 0)
truth <- test_imp$prolonged_los

confusionMatrix(factor(pred_class), factor(truth))
roc_obj <- roc(truth, pred_prob)
plot(roc_obj, col = "#4DB6AC")
auc(roc_obj)

```
The high sensitivity and low specificity suggest that the model gives more importance to the most class(class 0).

Run another fine-tuning 

```{r}
# Search sets of parameters more powerful
param_grid <- expand.grid(
  max_depth = c(3L, 4L),
  eta = c(0.01, 0.03),
  min_child_weight = c(5, 6),
  subsample = c(0.7,0.8),
  colsample_bytree = c(0.7),
  gamma = c(2, 3),
  scale_pos_weight = scale_pos_weight
)

best_auc <- 0
best_params <- list()

for (i in 1:nrow(param_grid)){
  params <- list(
    objective = "binary:logistic",
    eval_metric = "auc",
    max_depth = param_grid$max_depth[i],
    eta = param_grid$eta[i],
    subsample = param_grid$subsample[i],
    colsample_bytree = param_grid$colsample_bytree[i],
    min_child_weight = param_grid$min_child_weight[i],
    scale_pos_weight = scale_pos_weight,
    gamma = param_grid$gamma[i]
    
  )
  
  cat("\nRunning CV", i, "of", nrow(param_grid), "\n")
  
  cv_result <- xgb.cv(
    params = params,
    data = dtrain,
    nrounds = 5000,
    nfold = 5,
    metrics = c("auc","logloss"),
    early_stopping_rounds = 50,
    verbose = FALSE
  )
  
  best_iter <- cv_result$best_iteration
  mean_auc <- max(cv_result$evaluation_log$test_auc_mean)
  
  if (mean_auc > best_auc){
    best_auc <- mean_auc
    best_params <- params
    best_nrounds <- best_iter
    }
}

cat("\nBest AUC:", best_auc, "\n")
print(best_params)
cat("Best nround:", best_nrounds,"\n")
```
```{r}
xgb_best <- xgb.train(
  params = best_params,
  data = dtrain,
  nrounds = best_nrounds,
  watchlist = list(train = dtrain, test = dtest),
  early_stopping_rounds = 50,
  print_every_n = 50
)
```
```{r}
pred_prob <- predict(xgb_best, dtest)
pred_class <- ifelse(pred_prob >= 0.55, 1, 0)
truth <- test_imp$prolonged_los

confusionMatrix(factor(pred_class), factor(truth))
roc_obj <- roc(truth, pred_prob)
plot(roc_obj, col = "#4DB6AC")
auc(roc_obj)
```


```{r}
# 假设 lgb_pred_prob 已经包含测试集的预测概率

thresholds <- seq(0.1, 0.6, by = 0.05)
best_balanced_acc <- 0
best_threshold <- 0

cat("--- 阈值优化结果 ---\n")

for (t in thresholds) {
    # 预测类别
    pred_class <- ifelse(pred_prob >= t, 1, 0) # 假设 1 是延长住院

    # 计算混淆矩阵（需要 pROC 或 caret 包）
    conf_mat <- confusionMatrix(factor(pred_class), factor(y_test), positive = "1") # 假设 1 是延长住院的 'Positive' 类

    # 提取 Balanced Accuracy
    bal_acc <- conf_mat$byClass["Balanced Accuracy"] 

    cat(paste0("Threshold: ", format(t, digits=2), 
               ", Balanced Acc: ", format(bal_acc, digits=4), "\n"))

    if (bal_acc > best_balanced_acc) {
        best_balanced_acc <- bal_acc
        best_threshold <- t
    }
}

cat("\n--- 最佳结果 ---\n")
cat(paste0("最佳阈值: ", best_threshold, ", 最佳平衡准确率: ", format(best_balanced_acc, digits=4), "\n"))
```







```{r}
hr_lower <- 20
hr_upper <- 250
resp_lower <- 5
resp_upper <- 80
sysbp_lower <- 40
sysbp_upper <- 260
map_upper <- 30
map_lower <- 160
spo2_lower <- 50
spo2_upper <- 100
temp_lower <- 30
temp_upper <- 43
glucose_lower <- 40
glucose_upper <- 600

```

```{r}
vitals_24hr_clean <- vitals_hourly |>
  filter(hr >= 0 & hr <= 24) |>
 
  mutate(
    map_clean = case_when(
      meanarterialpressure < map_lower ~ map_lower,
      meanarterialpressure > map_upper ~ map_upper,
      TRUE ~ meanarterialpressure
    ),
    resp_clean = case_when(
      resprate < resp_lower ~ resp_lower,
      resprate > resp_upper ~ resp_upper,
      TRUE ~ resprate
    ),
    sysbp_clean = case_when(
      sysbp < sysbp_lower ~ sysbp_lower,
      sysbp > sysbp_upper ~ sysbp_upper,
      TRUE ~ sysbp
    ),
    hr_clean = case_when(
      heartrate < hr_lower ~ hr_lower,
      heartrate > hr_upper ~ hr_upper,
      TRUE ~ heartrate
    ),
    spo2_clean = case_when(
      spo2 < spo2_lower ~ spo2_lower,
      spo2 > spo2_upper ~ spo2_upper,
      TRUE ~ spo2
    ),
    temp_clean = case_when(
      temperature < temp_lower ~ temp_lower,
      temperature > temp_upper ~ temp_upper,
      TRUE ~ temperature
    ),
    glucose_clean = case_when(
      glucose < glucose_lower ~ glucose_lower,
      glucose > glucose_upper ~ glucose_upper,
      TRUE ~ glucose 
    )
  ) |>
  select(icustay_id, hr,map_clean, hr_clean, resp_clean, sysbp_clean, spo2_clean, temp_clean, glucose_clean) 
```


```{r}

vitals_24hr_locf <- vitals_24hr_clean %>%
  group_by(icustay_id) %>% 
  
  # Rank the records by time
  arrange(hr, .by_group = TRUE) %>% 
  
  fill(names(.)[!(names(.) %in% c("icustay_id", "hr"))], .direction = "down") %>%
  
  fill(names(.)[!(names(.) %in% c("icustay_id", "hr"))], .direction = "up") %>%
  
  ungroup()
```



```{r}
# Convert to long form
Vitals_long <- vitals_24hr_locf %>% 
  pivot_longer(
    cols = c(hr_clean, map_clean, sysbp_clean, temp_clean, glucose_clean, spo2_clean, resp_clean),
    names_to = "variable",
    values_to = "value"
  )


# Feature engineering
quantile_features <- Vitals_long |>
  group_by(icustay_id, variable) |>
  mutate(
    mean_val = mean(value, na.rm = TRUE),
    sd_val = sd(value, na.rm = TRUE)
  ) |>
  mutate(z = (value - mean_val)/sd_val) |>
  
  mutate(
    q_low = quantile(z, 0.25, na.rm = TRUE),
    q_high = quantile(z, 0.75, na.rm = TRUE)
  ) |>
  
  mutate(keep = z <= q_low | z >= q_high) |>
  
  summarise(
    n = n(),
    origin_mean = mean(value, na.rm = TRUE),
    origin_sd = ifelse(sum(!is.na(value)) > 1, sd(value, na.rm = TRUE),
                         ifelse(sum(!is.na(value)) == 1, 0, NA_real_)),
    mod_mean = ifelse(sum(keep, na.rm = TRUE) > 0,
                      mean(value[keep], na.rm = TRUE),
                      NA_real_),
    mod_sd   = ifelse(sum(keep, na.rm = TRUE) > 1,
                      sd(value[keep], na.rm = TRUE),
                      ifelse(sum(keep, na.rm = TRUE) == 1, 0, NA_real_)),
    quant_pct = ifelse(n > 0, sum(keep, na.rm = TRUE)/n, NA_real_),
    .groups = "drop"
  ) |>
  
  pivot_wider(
    names_from = variable, 
    values_from = c(origin_mean, origin_sd, mod_mean, mod_sd, quant_pct),
    names_glue = "{variable}_{.value}"
  ) |>
  
  mutate(across(
    where(is.numeric),
    function(x) ifelse(is.na(x), 1, 0),
    .names = "{.col}_missing"
  )) |>
  select(-icustay_id_missing, -n_missing)
```

```{r}
# Replace NA with 0
quantile_features_safe <- quantile_features |>
  mutate(across(everything(), ~replace_na(., 0)))
```

```{r}
# Merge with demographics and comorbidty data
data_merge2 <- pt_icu_outcome |>
  # Link the data tables
  left_join(
    icustays |> select(icustay_id, first_careunit),
    by = "icustay_id"
  ) |>
  mutate(
    icu_type = as.factor(first_careunit)
  ) |>
  
  left_join(
    patients |> select(subject_id, gender),
    by = "subject_id"
  ) |>
  
  left_join(
    admissions |> select(hadm_id, admission_type, insurance, ethnicity),
    by = "hadm_id"
  ) |>
  
  left_join(
    comorbidity_groups, by = "hadm_id"
  ) |>
  
  
  # Filter records of patients age >= 18
  filter(age_years >= 18) |>
    
  # Ensure exist of hospital outcome
  filter(!is.na(los)) |>

  mutate(
    # Binary indicator of length of stay
    prolonged_los = factor(ifelse(los >= 7, 1,0),
                           levels = c(0,1),
                           labels = c("short stay", "prolonged stay")),
    gender = as.factor(gender),               
    insurance = as.factor(insurance),         
    ethnicity = as.factor(ethnicity),         
    admission_type = as.factor(admission_type),
    first_careunit = as.factor(first_careunit),
    
    # Recode the ethnicity
    ethnicity = case_when(
      str_detect(ethnicity, "WHITE") ~ "WHITE",
      str_detect(ethnicity, "BLACK|AFRICAN AMERICAN") ~ "BLACK",
      str_detect(ethnicity, "HISPANIC|LATINO") ~ "HISPANIC",
      TRUE ~ "OTHER/UNKNOWN"
    ),
    ethnicity = as.factor(ethnicity)
  ) |>
  
  inner_join(
    quantile_features_safe,
    by = "icustay_id"
  ) |> 
  
  # Remove the one record with missing comorbidity information
  drop_na(comorb_cardio, comorb_pulm, comorb_cancer, comorb_other,
          comorb_renal, comorb_diabetes, comorb_liver) |>
  
  select(-row_id, -dob, -admittime, -dischtime, -intime, -outtime, -hosp_deathtime, -icu_expire_flag, -hospital_expire_flag, -dod, -expire_flag, -ttd_days, -n, -los)
```


```{r}
data_ml_ready <- data_merge2 |>
   mutate(
    prolonged_los = ifelse(prolonged_los == "prolonged stay", 1, 0)
  ) |>
  # One-hot coding
  fastDummies::dummy_cols(
  remove_first_dummy = TRUE, 
  remove_selected_columns = TRUE
)
```


```{r}
# Set random seed
set.seed(42)
ids <- unique(data_ml_ready$subject_id)
train_ids <- sample(ids, size = floor(0.8 * length(ids)))
train_idx <- data_ml_ready$subject_id %in% train_ids

train_data <- data_ml_ready[train_idx, ]
test_data <- data_ml_ready[!train_idx, ]

# Remove all ID columns
train_data <- train_data %>% select(-subject_id, -hadm_id, -icustay_id)
test_data <- test_data %>% select(-subject_id, -hadm_id, -icustay_id)

# Create DMatrix
y_train <- as.numeric(as.character(train_data$prolonged_los))
y_test <- as.numeric(as.character(test_data$prolonged_los))

dtrain <- xgboost::xgb.DMatrix(
  data = as.matrix(train_data %>% select(-prolonged_los)), 
  label = y_train
)

dtest <- xgboost::xgb.DMatrix(
  data = as.matrix(test_data %>% select(-prolonged_los)), 
  label = y_test
)
```

### Baseline model

```{r}
basic_params <- list(
    objective = "binary:logistic",
    eval_metric = "auc",
    max_depth = 5,
    eta = 0.1,
    subsample = 0.8,
    colsample_bytree = 0.8,
    min_child_weight = 2
)
```


```{r}
xgb_basic <- xgb.train(
  params = basic_params,
  data = dtrain,
  nrounds = 200,
  watchlist = list(train = dtrain, test = dtest),
  early_stopping_rounds = 20,
  print_every_n = 20
)
```

```{r}
# Simple evaluation of the baseline model
pred_basic <- predict(xgb_basic, dtest)
roc_basic <- roc(test_imp$prolonged_los, pred_basic)
auc_basic <- auc(roc_basic)
cat("Baseline Test AUC:", auc_basic, "\n")
```

```{r}
plot(roc_basic, col = "lightblue", main = "ROC Curve - Baseline Model")
```

### Fine-tuning
```{r}
# Define parameters
param_grid <- expand.grid(
  max_depth = c(3L,4L),
  eta = c(0.01,0.03),
  subsample = c(0.7),
  colsample_bytree = c(0.7),
  min_child_weight = c(5,6),
  gamma = c(2,3),
  KEEP.OUT.ATTRS = FALSE
)
```



```{r}
positive <- sum(train_data$prolonged_los == 1)
negative <- sum(train_data$prolonged_los == 0)
scale_pos_weight <- negative/positive
scale_pos_weight
```
```{r}
best_auc <- 0
best_params <- list()

for (i in 1:nrow(param_grid)){
  params <- list(
    objective = "binary:logistic",
    eval_metric = c("auc", "logloss"),
    max_depth = param_grid$max_depth[i],
    eta = param_grid$eta[i],
    subsample = param_grid$subsample[i],
    colsample_bytree = param_grid$colsample_bytree[i],
    min_child_weight = param_grid$min_child_weight[i],
    scale_pos_weight = scale_pos_weight,
    gamma = param_grid$gamma[i]
    
  )
  
  cat("\nRunning CV", i, "of", nrow(param_grid), "\n")
  
  cv_result <- xgb.cv(
    params = params,
    data = dtrain,
    nrounds = 1000,
    nfold = 5,
    metrics = c("auc", "logloss"),
    early_stopping_rounds = 20,
    verbose = FALSE
  )
  
  best_iter <- cv_result$best_iteration
  mean_auc <- max(cv_result$evaluation_log$test_auc_mean)
  
  if (mean_auc > best_auc){
    best_auc <- mean_auc
    best_params <- params
    best_nrounds <- best_iter
    }
}

cat("\nBest AUC:", best_auc, "\n")
print(best_params)
cat("Best nround:", best_nrounds,"\n")
```

Use the best parameters to train the model
```{r}
xgb_best <- xgb.train(
  params = best_params,
  data = dtrain,
  nrounds = best_nrounds,
  watchlist = list(train = dtrain, test = dtest),
  early_stopping_rounds = 20,
  print_every_n = 20
)
```

```{r}
pred_prob <- predict(xgb_best, dtest)
pred_class <- ifelse(pred_prob >= 0.55, 1, 0)
truth <- test_imp$prolonged_los

confusionMatrix(factor(pred_class), factor(truth))
roc_obj <- roc(truth, pred_prob)
plot(roc_obj, col = "lightblue")
auc(roc_obj)
```



"#E57373","#4DB6AC"

